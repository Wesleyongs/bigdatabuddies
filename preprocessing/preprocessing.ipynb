{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2_4_concat.csv')\n",
    "\n",
    "\n",
    "#test on feb 21 data\n",
    "\n",
    "# date = \"feb21\"\n",
    "\n",
    "# df = pd.read_csv(f'feb_preprocessed/preprocessed_{date}.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime     0\n",
       "id           0\n",
       "text        51\n",
       "username     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with NaN\n",
    "\n",
    "# df = df.dropna(inplace = True)\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    0\n",
       "id          0\n",
       "text        0\n",
       "username    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jewel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jewel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jewel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jewel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#For Preprocessing\n",
    "import re    # RegEx for removing non-letter characters\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import sys\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.parse.malt import MaltParser\n",
    "from nltk.corpus import words\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import html\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jewel\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(text):\n",
    "    # remove non-ASCII characters in string\n",
    "    decoded_text = text.encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # decode HTML entities\n",
    "    decoded_html = html.unescape(decoded_text)\n",
    "    return ''.join([word for word in decoded_html if word.isprintable()])\n",
    "\n",
    "def remove_mentions(text):\n",
    "    return re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "\n",
    "def remove_stopwords(words_list):\n",
    "    stop_list = stopwords.words(\"english\")\n",
    "    stop_list.append(\"filler\")\n",
    "    return [word for word in words_list if word not in stop_list]\n",
    "\n",
    "def pos_to_wordnet(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_words(word_list):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    # POS (part-of-speech) tagging\n",
    "    # nltk_tagged -> a list of tuples (word, pos tag)\n",
    "    nltk_tagged = nltk.pos_tag(word_list)\n",
    "\n",
    "    # returns a list of tuples of words and their wordnet_tag (after conversion from NLTK tag)\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_to_wordnet(x[1])), nltk_tagged))\n",
    "\n",
    "    # lemmatizing\n",
    "    lemmatized_words = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is not None:\n",
    "            # need POS tag as 2nd argument as it helps lemmatize the words more accurately\n",
    "            lemmatized_words.append(lemmatizer.lemmatize(word, tag))\n",
    "        elif tag in [wordnet.NOUN]:\n",
    "            lemmatized_words.append(lemmatizer.lemmatize(word))\n",
    "    return lemmatized_words\n",
    "\n",
    "def clean_original_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    clean_list = []\n",
    "    sentence_list = nltk.sent_tokenize(text)\n",
    "    for sentence in sentence_list:\n",
    "        decoded_sentence = decode_text(sentence)\n",
    "        words_list = nltk.RegexpTokenizer(r'\\w+').tokenize(decoded_sentence)\n",
    "        lemmatized_words = lemmatize_words(words_list)\n",
    "        useful_words = remove_stopwords(lemmatized_words)\n",
    "\n",
    "        if len(useful_words) > 0:\n",
    "            clean_list.extend(useful_words)\n",
    "    clean_text = ' '.join(clean_list)\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED CLEANING\n"
     ]
    }
   ],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_original_text)\n",
    "df['clean_tokens'] = df['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "print(\"COMPLETED CLEANING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-13 23:59:12</td>\n",
       "      <td>j48y2ja</td>\n",
       "      <td>ChatGPT info on illicit material  especially w...</td>\n",
       "      <td>Massive-Mountain7157</td>\n",
       "      <td>chatgpt info illicit material especially use d...</td>\n",
       "      <td>[ChatGPT, info, on, illicit, material, especia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-13 23:58:49</td>\n",
       "      <td>j48y0mm</td>\n",
       "      <td>Good luck dude  let us know how it goes</td>\n",
       "      <td>devdeltek</td>\n",
       "      <td>good luck dude let know go</td>\n",
       "      <td>[Good, luck, dude, let, us, know, how, it, goes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-13 23:58:40</td>\n",
       "      <td>j48xzxu</td>\n",
       "      <td>I personally think there s a good chance it s ...</td>\n",
       "      <td>kptkrunch</td>\n",
       "      <td>personally think good chance matter scale poin...</td>\n",
       "      <td>[I, personally, think, there, s, a, good, chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-13 23:58:33</td>\n",
       "      <td>j48xzcu</td>\n",
       "      <td>Bro wha</td>\n",
       "      <td>Charlie_2504</td>\n",
       "      <td>bro wha</td>\n",
       "      <td>[Bro, wha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-13 23:58:05</td>\n",
       "      <td>j48xx1b</td>\n",
       "      <td>I asked ChatGPT to rewrite the prompt in a way...</td>\n",
       "      <td>KrazyA1pha</td>\n",
       "      <td>ask chatgpt rewrite prompt way best understand...</td>\n",
       "      <td>[I, asked, ChatGPT, to, rewrite, the, prompt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541594</th>\n",
       "      <td>2023-01-09 00:02:30</td>\n",
       "      <td>j3jfixn</td>\n",
       "      <td>Probably just compiling all the dystopian fict...</td>\n",
       "      <td>VanEngine</td>\n",
       "      <td>probably compile dystopian fiction human make ...</td>\n",
       "      <td>[Probably, just, compiling, all, the, dystopia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541595</th>\n",
       "      <td>2023-01-09 00:01:59</td>\n",
       "      <td>j3jfg2v</td>\n",
       "      <td>It is indeed very much a superpower but as far...</td>\n",
       "      <td>frankIIe</td>\n",
       "      <td>indeed much superpower far concern dozen quest...</td>\n",
       "      <td>[It, is, indeed, very, much, a, superpower, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541596</th>\n",
       "      <td>2023-01-09 00:01:18</td>\n",
       "      <td>j3jfch3</td>\n",
       "      <td>That s exactly what I was saying to my husband...</td>\n",
       "      <td>No-Bear1059</td>\n",
       "      <td>exactly say husband day</td>\n",
       "      <td>[That, s, exactly, what, I, was, saying, to, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541597</th>\n",
       "      <td>2023-01-09 00:00:51</td>\n",
       "      <td>j3jfa4v</td>\n",
       "      <td>Amazing tip  Thanks</td>\n",
       "      <td>alan65011</td>\n",
       "      <td>amaze tip thanks</td>\n",
       "      <td>[Amazing, tip, Thanks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541598</th>\n",
       "      <td>2023-01-09 00:00:18</td>\n",
       "      <td>j3jf73l</td>\n",
       "      <td>Year s for some</td>\n",
       "      <td>Egospartan_</td>\n",
       "      <td>year</td>\n",
       "      <td>[Year, s, for, some]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2541548 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime       id  \\\n",
       "0        2023-01-13 23:59:12  j48y2ja   \n",
       "1        2023-01-13 23:58:49  j48y0mm   \n",
       "2        2023-01-13 23:58:40  j48xzxu   \n",
       "3        2023-01-13 23:58:33  j48xzcu   \n",
       "4        2023-01-13 23:58:05  j48xx1b   \n",
       "...                      ...      ...   \n",
       "2541594  2023-01-09 00:02:30  j3jfixn   \n",
       "2541595  2023-01-09 00:01:59  j3jfg2v   \n",
       "2541596  2023-01-09 00:01:18  j3jfch3   \n",
       "2541597  2023-01-09 00:00:51  j3jfa4v   \n",
       "2541598  2023-01-09 00:00:18  j3jf73l   \n",
       "\n",
       "                                                      text  \\\n",
       "0        ChatGPT info on illicit material  especially w...   \n",
       "1                 Good luck dude  let us know how it goes    \n",
       "2        I personally think there s a good chance it s ...   \n",
       "3                                                 Bro wha    \n",
       "4        I asked ChatGPT to rewrite the prompt in a way...   \n",
       "...                                                    ...   \n",
       "2541594  Probably just compiling all the dystopian fict...   \n",
       "2541595  It is indeed very much a superpower but as far...   \n",
       "2541596  That s exactly what I was saying to my husband...   \n",
       "2541597                               Amazing tip  Thanks    \n",
       "2541598                                    Year s for some   \n",
       "\n",
       "                     username  \\\n",
       "0        Massive-Mountain7157   \n",
       "1                   devdeltek   \n",
       "2                   kptkrunch   \n",
       "3                Charlie_2504   \n",
       "4                  KrazyA1pha   \n",
       "...                       ...   \n",
       "2541594             VanEngine   \n",
       "2541595              frankIIe   \n",
       "2541596           No-Bear1059   \n",
       "2541597             alan65011   \n",
       "2541598           Egospartan_   \n",
       "\n",
       "                                                clean_text  \\\n",
       "0        chatgpt info illicit material especially use d...   \n",
       "1                               good luck dude let know go   \n",
       "2        personally think good chance matter scale poin...   \n",
       "3                                                  bro wha   \n",
       "4        ask chatgpt rewrite prompt way best understand...   \n",
       "...                                                    ...   \n",
       "2541594  probably compile dystopian fiction human make ...   \n",
       "2541595  indeed much superpower far concern dozen quest...   \n",
       "2541596                            exactly say husband day   \n",
       "2541597                                   amaze tip thanks   \n",
       "2541598                                               year   \n",
       "\n",
       "                                              clean_tokens  \n",
       "0        [ChatGPT, info, on, illicit, material, especia...  \n",
       "1         [Good, luck, dude, let, us, know, how, it, goes]  \n",
       "2        [I, personally, think, there, s, a, good, chan...  \n",
       "3                                               [Bro, wha]  \n",
       "4        [I, asked, ChatGPT, to, rewrite, the, prompt, ...  \n",
       "...                                                    ...  \n",
       "2541594  [Probably, just, compiling, all, the, dystopia...  \n",
       "2541595  [It, is, indeed, very, much, a, superpower, bu...  \n",
       "2541596  [That, s, exactly, what, I, was, saying, to, m...  \n",
       "2541597                             [Amazing, tip, Thanks]  \n",
       "2541598                               [Year, s, for, some]  \n",
       "\n",
       "[2541548 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"2_4_preprocessed.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp value for date\n",
    "date = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jewel\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## VADER\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "# NLTK VADER for sentiment analysis\n",
    "\n",
    "# New words and values\n",
    "# New words and values\n",
    "new_words = {\n",
    "    'easy-to-use': 10,\n",
    "    'productive': 5,\n",
    "    'slow': -5,\n",
    "    'frustrating': -10,\n",
    "    'glitchy': -100,\n",
    "}\n",
    "\n",
    "# Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "# Update the lexicon\n",
    "vader.lexicon.update(new_words)\n",
    "\n",
    "print('ok!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-13 23:59:12</td>\n",
       "      <td>j48y2ja</td>\n",
       "      <td>ChatGPT info on illicit material  especially w...</td>\n",
       "      <td>Massive-Mountain7157</td>\n",
       "      <td>chatgpt info illicit material especially use d...</td>\n",
       "      <td>[ChatGPT, info, on, illicit, material, especia...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-13 23:58:49</td>\n",
       "      <td>j48y0mm</td>\n",
       "      <td>Good luck dude  let us know how it goes</td>\n",
       "      <td>devdeltek</td>\n",
       "      <td>good luck dude let know go</td>\n",
       "      <td>[Good, luck, dude, let, us, know, how, it, goes]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-13 23:58:40</td>\n",
       "      <td>j48xzxu</td>\n",
       "      <td>I personally think there s a good chance it s ...</td>\n",
       "      <td>kptkrunch</td>\n",
       "      <td>personally think good chance matter scale poin...</td>\n",
       "      <td>[I, personally, think, there, s, a, good, chan...</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.9274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-13 23:58:33</td>\n",
       "      <td>j48xzcu</td>\n",
       "      <td>Bro wha</td>\n",
       "      <td>Charlie_2504</td>\n",
       "      <td>bro wha</td>\n",
       "      <td>[Bro, wha]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-13 23:58:05</td>\n",
       "      <td>j48xx1b</td>\n",
       "      <td>I asked ChatGPT to rewrite the prompt in a way...</td>\n",
       "      <td>KrazyA1pha</td>\n",
       "      <td>ask chatgpt rewrite prompt way best understand...</td>\n",
       "      <td>[I, asked, ChatGPT, to, rewrite, the, prompt, ...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.9867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime       id  \\\n",
       "0  2023-01-13 23:59:12  j48y2ja   \n",
       "1  2023-01-13 23:58:49  j48y0mm   \n",
       "2  2023-01-13 23:58:40  j48xzxu   \n",
       "3  2023-01-13 23:58:33  j48xzcu   \n",
       "4  2023-01-13 23:58:05  j48xx1b   \n",
       "\n",
       "                                                text              username  \\\n",
       "0  ChatGPT info on illicit material  especially w...  Massive-Mountain7157   \n",
       "1           Good luck dude  let us know how it goes              devdeltek   \n",
       "2  I personally think there s a good chance it s ...             kptkrunch   \n",
       "3                                           Bro wha           Charlie_2504   \n",
       "4  I asked ChatGPT to rewrite the prompt in a way...            KrazyA1pha   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  chatgpt info illicit material especially use d...   \n",
       "1                         good luck dude let know go   \n",
       "2  personally think good chance matter scale poin...   \n",
       "3                                            bro wha   \n",
       "4  ask chatgpt rewrite prompt way best understand...   \n",
       "\n",
       "                                        clean_tokens    neg    neu    pos  \\\n",
       "0  [ChatGPT, info, on, illicit, material, especia...  0.000  0.836  0.164   \n",
       "1   [Good, luck, dude, let, us, know, how, it, goes]  0.000  0.404  0.596   \n",
       "2  [I, personally, think, there, s, a, good, chan...  0.036  0.678  0.286   \n",
       "3                                         [Bro, wha]  0.000  1.000  0.000   \n",
       "4  [I, asked, ChatGPT, to, rewrite, the, prompt, ...  0.027  0.714  0.259   \n",
       "\n",
       "   compound  \n",
       "0    0.7703  \n",
       "1    0.7096  \n",
       "2    0.9274  \n",
       "3    0.0000  \n",
       "4    0.9867  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Iterate through the headlines and get the polarity scores\n",
    "scores = df['clean_text'].apply(vader.polarity_scores)\n",
    "\n",
    "# Convert the list of dicts into a DataFrame\n",
    "scores_df = pd.DataFrame.from_records(scores)\n",
    "\n",
    "# Join the DataFrames\n",
    "scored_tweets = df.join(scores_df)\n",
    "scored_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets.to_csv(\"2_4_vader.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-13 23:59:12</td>\n",
       "      <td>j48y2ja</td>\n",
       "      <td>ChatGPT info on illicit material  especially w...</td>\n",
       "      <td>Massive-Mountain7157</td>\n",
       "      <td>chatgpt info illicit material especially use d...</td>\n",
       "      <td>['ChatGPT', 'info', 'on', 'illicit', 'material...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-13 23:58:49</td>\n",
       "      <td>j48y0mm</td>\n",
       "      <td>Good luck dude  let us know how it goes</td>\n",
       "      <td>devdeltek</td>\n",
       "      <td>good luck dude let know go</td>\n",
       "      <td>['Good', 'luck', 'dude', 'let', 'us', 'know', ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-13 23:58:40</td>\n",
       "      <td>j48xzxu</td>\n",
       "      <td>I personally think there s a good chance it s ...</td>\n",
       "      <td>kptkrunch</td>\n",
       "      <td>personally think good chance matter scale poin...</td>\n",
       "      <td>['I', 'personally', 'think', 'there', 's', 'a'...</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.9274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-13 23:58:33</td>\n",
       "      <td>j48xzcu</td>\n",
       "      <td>Bro wha</td>\n",
       "      <td>Charlie_2504</td>\n",
       "      <td>bro wha</td>\n",
       "      <td>['Bro', 'wha']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-13 23:58:05</td>\n",
       "      <td>j48xx1b</td>\n",
       "      <td>I asked ChatGPT to rewrite the prompt in a way...</td>\n",
       "      <td>KrazyA1pha</td>\n",
       "      <td>ask chatgpt rewrite prompt way best understand...</td>\n",
       "      <td>['I', 'asked', 'ChatGPT', 'to', 'rewrite', 'th...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.9867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541543</th>\n",
       "      <td>2541594</td>\n",
       "      <td>2023-01-09 00:02:30</td>\n",
       "      <td>j3jfixn</td>\n",
       "      <td>Probably just compiling all the dystopian fict...</td>\n",
       "      <td>VanEngine</td>\n",
       "      <td>probably compile dystopian fiction human make ...</td>\n",
       "      <td>['Probably', 'just', 'compiling', 'all', 'the'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541544</th>\n",
       "      <td>2541595</td>\n",
       "      <td>2023-01-09 00:01:59</td>\n",
       "      <td>j3jfg2v</td>\n",
       "      <td>It is indeed very much a superpower but as far...</td>\n",
       "      <td>frankIIe</td>\n",
       "      <td>indeed much superpower far concern dozen quest...</td>\n",
       "      <td>['It', 'is', 'indeed', 'very', 'much', 'a', 's...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541545</th>\n",
       "      <td>2541596</td>\n",
       "      <td>2023-01-09 00:01:18</td>\n",
       "      <td>j3jfch3</td>\n",
       "      <td>That s exactly what I was saying to my husband...</td>\n",
       "      <td>No-Bear1059</td>\n",
       "      <td>exactly say husband day</td>\n",
       "      <td>['That', 's', 'exactly', 'what', 'I', 'was', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541546</th>\n",
       "      <td>2541597</td>\n",
       "      <td>2023-01-09 00:00:51</td>\n",
       "      <td>j3jfa4v</td>\n",
       "      <td>Amazing tip  Thanks</td>\n",
       "      <td>alan65011</td>\n",
       "      <td>amaze tip thanks</td>\n",
       "      <td>['Amazing', 'tip', 'Thanks']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541547</th>\n",
       "      <td>2541598</td>\n",
       "      <td>2023-01-09 00:00:18</td>\n",
       "      <td>j3jf73l</td>\n",
       "      <td>Year s for some</td>\n",
       "      <td>Egospartan_</td>\n",
       "      <td>year</td>\n",
       "      <td>['Year', 's', 'for', 'some']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2541548 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             datetime       id  \\\n",
       "0                 0  2023-01-13 23:59:12  j48y2ja   \n",
       "1                 1  2023-01-13 23:58:49  j48y0mm   \n",
       "2                 2  2023-01-13 23:58:40  j48xzxu   \n",
       "3                 3  2023-01-13 23:58:33  j48xzcu   \n",
       "4                 4  2023-01-13 23:58:05  j48xx1b   \n",
       "...             ...                  ...      ...   \n",
       "2541543     2541594  2023-01-09 00:02:30  j3jfixn   \n",
       "2541544     2541595  2023-01-09 00:01:59  j3jfg2v   \n",
       "2541545     2541596  2023-01-09 00:01:18  j3jfch3   \n",
       "2541546     2541597  2023-01-09 00:00:51  j3jfa4v   \n",
       "2541547     2541598  2023-01-09 00:00:18  j3jf73l   \n",
       "\n",
       "                                                      text  \\\n",
       "0        ChatGPT info on illicit material  especially w...   \n",
       "1                 Good luck dude  let us know how it goes    \n",
       "2        I personally think there s a good chance it s ...   \n",
       "3                                                 Bro wha    \n",
       "4        I asked ChatGPT to rewrite the prompt in a way...   \n",
       "...                                                    ...   \n",
       "2541543  Probably just compiling all the dystopian fict...   \n",
       "2541544  It is indeed very much a superpower but as far...   \n",
       "2541545  That s exactly what I was saying to my husband...   \n",
       "2541546                               Amazing tip  Thanks    \n",
       "2541547                                    Year s for some   \n",
       "\n",
       "                     username  \\\n",
       "0        Massive-Mountain7157   \n",
       "1                   devdeltek   \n",
       "2                   kptkrunch   \n",
       "3                Charlie_2504   \n",
       "4                  KrazyA1pha   \n",
       "...                       ...   \n",
       "2541543             VanEngine   \n",
       "2541544              frankIIe   \n",
       "2541545           No-Bear1059   \n",
       "2541546             alan65011   \n",
       "2541547           Egospartan_   \n",
       "\n",
       "                                                clean_text  \\\n",
       "0        chatgpt info illicit material especially use d...   \n",
       "1                               good luck dude let know go   \n",
       "2        personally think good chance matter scale poin...   \n",
       "3                                                  bro wha   \n",
       "4        ask chatgpt rewrite prompt way best understand...   \n",
       "...                                                    ...   \n",
       "2541543  probably compile dystopian fiction human make ...   \n",
       "2541544  indeed much superpower far concern dozen quest...   \n",
       "2541545                            exactly say husband day   \n",
       "2541546                                   amaze tip thanks   \n",
       "2541547                                               year   \n",
       "\n",
       "                                              clean_tokens    neg    neu  \\\n",
       "0        ['ChatGPT', 'info', 'on', 'illicit', 'material...  0.000  0.836   \n",
       "1        ['Good', 'luck', 'dude', 'let', 'us', 'know', ...  0.000  0.404   \n",
       "2        ['I', 'personally', 'think', 'there', 's', 'a'...  0.036  0.678   \n",
       "3                                           ['Bro', 'wha']  0.000  1.000   \n",
       "4        ['I', 'asked', 'ChatGPT', 'to', 'rewrite', 'th...  0.027  0.714   \n",
       "...                                                    ...    ...    ...   \n",
       "2541543  ['Probably', 'just', 'compiling', 'all', 'the'...    NaN    NaN   \n",
       "2541544  ['It', 'is', 'indeed', 'very', 'much', 'a', 's...    NaN    NaN   \n",
       "2541545  ['That', 's', 'exactly', 'what', 'I', 'was', '...    NaN    NaN   \n",
       "2541546                       ['Amazing', 'tip', 'Thanks']    NaN    NaN   \n",
       "2541547                       ['Year', 's', 'for', 'some']    NaN    NaN   \n",
       "\n",
       "           pos  compound  \n",
       "0        0.164    0.7703  \n",
       "1        0.596    0.7096  \n",
       "2        0.286    0.9274  \n",
       "3        0.000    0.0000  \n",
       "4        0.259    0.9867  \n",
       "...        ...       ...  \n",
       "2541543    NaN       NaN  \n",
       "2541544    NaN       NaN  \n",
       "2541545    NaN       NaN  \n",
       "2541546    NaN       NaN  \n",
       "2541547    NaN       NaN  \n",
       "\n",
       "[2541548 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "scored_tweets_vader = pd.read_csv(\"2_4_vader.csv\")\n",
    "scored_tweets_vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "datetime            0\n",
       "id                  0\n",
       "text                0\n",
       "username            0\n",
       "clean_text      34164\n",
       "clean_tokens        0\n",
       "neg                51\n",
       "neu                51\n",
       "pos                51\n",
       "compound           51\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets_vader.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-13 23:59:12</td>\n",
       "      <td>j48y2ja</td>\n",
       "      <td>ChatGPT info on illicit material  especially w...</td>\n",
       "      <td>Massive-Mountain7157</td>\n",
       "      <td>chatgpt info illicit material especially use d...</td>\n",
       "      <td>['ChatGPT', 'info', 'on', 'illicit', 'material...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-13 23:58:49</td>\n",
       "      <td>j48y0mm</td>\n",
       "      <td>Good luck dude  let us know how it goes</td>\n",
       "      <td>devdeltek</td>\n",
       "      <td>good luck dude let know go</td>\n",
       "      <td>['Good', 'luck', 'dude', 'let', 'us', 'know', ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-13 23:58:40</td>\n",
       "      <td>j48xzxu</td>\n",
       "      <td>I personally think there s a good chance it s ...</td>\n",
       "      <td>kptkrunch</td>\n",
       "      <td>personally think good chance matter scale poin...</td>\n",
       "      <td>['I', 'personally', 'think', 'there', 's', 'a'...</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.9274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-13 23:58:33</td>\n",
       "      <td>j48xzcu</td>\n",
       "      <td>Bro wha</td>\n",
       "      <td>Charlie_2504</td>\n",
       "      <td>bro wha</td>\n",
       "      <td>['Bro', 'wha']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-13 23:58:05</td>\n",
       "      <td>j48xx1b</td>\n",
       "      <td>I asked ChatGPT to rewrite the prompt in a way...</td>\n",
       "      <td>KrazyA1pha</td>\n",
       "      <td>ask chatgpt rewrite prompt way best understand...</td>\n",
       "      <td>['I', 'asked', 'ChatGPT', 'to', 'rewrite', 'th...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.9867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541543</th>\n",
       "      <td>2023-01-09 00:02:30</td>\n",
       "      <td>j3jfixn</td>\n",
       "      <td>Probably just compiling all the dystopian fict...</td>\n",
       "      <td>VanEngine</td>\n",
       "      <td>probably compile dystopian fiction human make ...</td>\n",
       "      <td>['Probably', 'just', 'compiling', 'all', 'the'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541544</th>\n",
       "      <td>2023-01-09 00:01:59</td>\n",
       "      <td>j3jfg2v</td>\n",
       "      <td>It is indeed very much a superpower but as far...</td>\n",
       "      <td>frankIIe</td>\n",
       "      <td>indeed much superpower far concern dozen quest...</td>\n",
       "      <td>['It', 'is', 'indeed', 'very', 'much', 'a', 's...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541545</th>\n",
       "      <td>2023-01-09 00:01:18</td>\n",
       "      <td>j3jfch3</td>\n",
       "      <td>That s exactly what I was saying to my husband...</td>\n",
       "      <td>No-Bear1059</td>\n",
       "      <td>exactly say husband day</td>\n",
       "      <td>['That', 's', 'exactly', 'what', 'I', 'was', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541546</th>\n",
       "      <td>2023-01-09 00:00:51</td>\n",
       "      <td>j3jfa4v</td>\n",
       "      <td>Amazing tip  Thanks</td>\n",
       "      <td>alan65011</td>\n",
       "      <td>amaze tip thanks</td>\n",
       "      <td>['Amazing', 'tip', 'Thanks']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541547</th>\n",
       "      <td>2023-01-09 00:00:18</td>\n",
       "      <td>j3jf73l</td>\n",
       "      <td>Year s for some</td>\n",
       "      <td>Egospartan_</td>\n",
       "      <td>year</td>\n",
       "      <td>['Year', 's', 'for', 'some']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2541548 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime       id  \\\n",
       "0        2023-01-13 23:59:12  j48y2ja   \n",
       "1        2023-01-13 23:58:49  j48y0mm   \n",
       "2        2023-01-13 23:58:40  j48xzxu   \n",
       "3        2023-01-13 23:58:33  j48xzcu   \n",
       "4        2023-01-13 23:58:05  j48xx1b   \n",
       "...                      ...      ...   \n",
       "2541543  2023-01-09 00:02:30  j3jfixn   \n",
       "2541544  2023-01-09 00:01:59  j3jfg2v   \n",
       "2541545  2023-01-09 00:01:18  j3jfch3   \n",
       "2541546  2023-01-09 00:00:51  j3jfa4v   \n",
       "2541547  2023-01-09 00:00:18  j3jf73l   \n",
       "\n",
       "                                                      text  \\\n",
       "0        ChatGPT info on illicit material  especially w...   \n",
       "1                 Good luck dude  let us know how it goes    \n",
       "2        I personally think there s a good chance it s ...   \n",
       "3                                                 Bro wha    \n",
       "4        I asked ChatGPT to rewrite the prompt in a way...   \n",
       "...                                                    ...   \n",
       "2541543  Probably just compiling all the dystopian fict...   \n",
       "2541544  It is indeed very much a superpower but as far...   \n",
       "2541545  That s exactly what I was saying to my husband...   \n",
       "2541546                               Amazing tip  Thanks    \n",
       "2541547                                    Year s for some   \n",
       "\n",
       "                     username  \\\n",
       "0        Massive-Mountain7157   \n",
       "1                   devdeltek   \n",
       "2                   kptkrunch   \n",
       "3                Charlie_2504   \n",
       "4                  KrazyA1pha   \n",
       "...                       ...   \n",
       "2541543             VanEngine   \n",
       "2541544              frankIIe   \n",
       "2541545           No-Bear1059   \n",
       "2541546             alan65011   \n",
       "2541547           Egospartan_   \n",
       "\n",
       "                                                clean_text  \\\n",
       "0        chatgpt info illicit material especially use d...   \n",
       "1                               good luck dude let know go   \n",
       "2        personally think good chance matter scale poin...   \n",
       "3                                                  bro wha   \n",
       "4        ask chatgpt rewrite prompt way best understand...   \n",
       "...                                                    ...   \n",
       "2541543  probably compile dystopian fiction human make ...   \n",
       "2541544  indeed much superpower far concern dozen quest...   \n",
       "2541545                            exactly say husband day   \n",
       "2541546                                   amaze tip thanks   \n",
       "2541547                                               year   \n",
       "\n",
       "                                              clean_tokens    neg    neu  \\\n",
       "0        ['ChatGPT', 'info', 'on', 'illicit', 'material...  0.000  0.836   \n",
       "1        ['Good', 'luck', 'dude', 'let', 'us', 'know', ...  0.000  0.404   \n",
       "2        ['I', 'personally', 'think', 'there', 's', 'a'...  0.036  0.678   \n",
       "3                                           ['Bro', 'wha']  0.000  1.000   \n",
       "4        ['I', 'asked', 'ChatGPT', 'to', 'rewrite', 'th...  0.027  0.714   \n",
       "...                                                    ...    ...    ...   \n",
       "2541543  ['Probably', 'just', 'compiling', 'all', 'the'...    NaN    NaN   \n",
       "2541544  ['It', 'is', 'indeed', 'very', 'much', 'a', 's...    NaN    NaN   \n",
       "2541545  ['That', 's', 'exactly', 'what', 'I', 'was', '...    NaN    NaN   \n",
       "2541546                       ['Amazing', 'tip', 'Thanks']    NaN    NaN   \n",
       "2541547                       ['Year', 's', 'for', 'some']    NaN    NaN   \n",
       "\n",
       "           pos  compound  \n",
       "0        0.164    0.7703  \n",
       "1        0.596    0.7096  \n",
       "2        0.286    0.9274  \n",
       "3        0.000    0.0000  \n",
       "4        0.259    0.9867  \n",
       "...        ...       ...  \n",
       "2541543    NaN       NaN  \n",
       "2541544    NaN       NaN  \n",
       "2541545    NaN       NaN  \n",
       "2541546    NaN       NaN  \n",
       "2541547    NaN       NaN  \n",
       "\n",
       "[2541548 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets_vader.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "scored_tweets_vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jewel\\AppData\\Local\\Temp\\ipykernel_8160\\4094744925.py:15: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_daily = scored_tweets_vader.resample('D').mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>0.061464</td>\n",
       "      <td>0.772297</td>\n",
       "      <td>0.166158</td>\n",
       "      <td>0.212533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-03</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>0.777708</td>\n",
       "      <td>0.161076</td>\n",
       "      <td>0.202205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>0.043140</td>\n",
       "      <td>0.842057</td>\n",
       "      <td>0.114802</td>\n",
       "      <td>0.142914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>0.106032</td>\n",
       "      <td>0.692537</td>\n",
       "      <td>0.190728</td>\n",
       "      <td>0.154342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>0.096618</td>\n",
       "      <td>0.717403</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.149509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>0.128494</td>\n",
       "      <td>0.649595</td>\n",
       "      <td>0.212027</td>\n",
       "      <td>0.136985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>0.078851</td>\n",
       "      <td>0.671704</td>\n",
       "      <td>0.234834</td>\n",
       "      <td>0.255941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>0.116590</td>\n",
       "      <td>0.659031</td>\n",
       "      <td>0.209264</td>\n",
       "      <td>0.134794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       neg       neu       pos  compound\n",
       "0    2022-12-02  0.061464  0.772297  0.166158  0.212533\n",
       "1    2022-12-03  0.061216  0.777708  0.161076  0.202205\n",
       "2    2022-12-04  0.043140  0.842057  0.114802  0.142914\n",
       "3    2022-12-05       NaN       NaN       NaN       NaN\n",
       "4    2022-12-06       NaN       NaN       NaN       NaN\n",
       "..          ...       ...       ...       ...       ...\n",
       "115  2023-03-27  0.106032  0.692537  0.190728  0.154342\n",
       "116  2023-03-28  0.096618  0.717403  0.168647  0.149509\n",
       "117  2023-03-29  0.128494  0.649595  0.212027  0.136985\n",
       "118  2023-03-30  0.078851  0.671704  0.234834  0.255941\n",
       "119  2023-03-31  0.116590  0.659031  0.209264  0.134794\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pytz import timezone\n",
    "\n",
    "# Convert 'Datetime' column to datetime type (assuming it's in UTC)\n",
    "scored_tweets_vader['datetime'] = pd.to_datetime(scored_tweets_vader['datetime'], utc=True)\n",
    "scored_tweets_vader\n",
    "\n",
    "# Set 'Datetime' column as index (still timezone-aware)\n",
    "scored_tweets_vader.set_index('datetime', inplace=True)\n",
    "\n",
    "# Convert index to timezone-naive\n",
    "scored_tweets_vader.index = scored_tweets_vader.index.tz_localize(None)\n",
    "\n",
    "# Calculate daily averages and create new dataframe\n",
    "df_daily = scored_tweets_vader.resample('D').mean()\n",
    "\n",
    "# Add 'Date' column to new dataframe\n",
    "df_daily['Date'] = df_daily.index.date\n",
    "\n",
    "# Reset index (index is still timezone-naive)\n",
    "df_daily.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "df_daily = df_daily[['Date', 'neg', 'neu', 'pos', 'compound']]\n",
    "df_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>0.061464</td>\n",
       "      <td>0.772297</td>\n",
       "      <td>0.166158</td>\n",
       "      <td>0.212533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-03</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>0.777708</td>\n",
       "      <td>0.161076</td>\n",
       "      <td>0.202205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>0.043140</td>\n",
       "      <td>0.842057</td>\n",
       "      <td>0.114802</td>\n",
       "      <td>0.142914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>0.106032</td>\n",
       "      <td>0.692537</td>\n",
       "      <td>0.190728</td>\n",
       "      <td>0.154342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>0.096618</td>\n",
       "      <td>0.717403</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.149509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>0.128494</td>\n",
       "      <td>0.649595</td>\n",
       "      <td>0.212027</td>\n",
       "      <td>0.136985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>0.078851</td>\n",
       "      <td>0.671704</td>\n",
       "      <td>0.234834</td>\n",
       "      <td>0.255941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>0.116590</td>\n",
       "      <td>0.659031</td>\n",
       "      <td>0.209264</td>\n",
       "      <td>0.134794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       neg       neu       pos  compound\n",
       "0    2022-12-02  0.061464  0.772297  0.166158  0.212533\n",
       "1    2022-12-03  0.061216  0.777708  0.161076  0.202205\n",
       "2    2022-12-04  0.043140  0.842057  0.114802  0.142914\n",
       "3    2022-12-05       NaN       NaN       NaN       NaN\n",
       "4    2022-12-06       NaN       NaN       NaN       NaN\n",
       "..          ...       ...       ...       ...       ...\n",
       "115  2023-03-27  0.106032  0.692537  0.190728  0.154342\n",
       "116  2023-03-28  0.096618  0.717403  0.168647  0.149509\n",
       "117  2023-03-29  0.128494  0.649595  0.212027  0.136985\n",
       "118  2023-03-30  0.078851  0.671704  0.234834  0.255941\n",
       "119  2023-03-31  0.116590  0.659031  0.209264  0.134794\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_copy = df_daily.copy()\n",
    "df_daily_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>0.061464</td>\n",
       "      <td>0.772297</td>\n",
       "      <td>0.166158</td>\n",
       "      <td>0.212533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-03</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>0.777708</td>\n",
       "      <td>0.161076</td>\n",
       "      <td>0.202205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>0.043140</td>\n",
       "      <td>0.842057</td>\n",
       "      <td>0.114802</td>\n",
       "      <td>0.142914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>0.106032</td>\n",
       "      <td>0.692537</td>\n",
       "      <td>0.190728</td>\n",
       "      <td>0.154342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>0.096618</td>\n",
       "      <td>0.717403</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.149509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>0.128494</td>\n",
       "      <td>0.649595</td>\n",
       "      <td>0.212027</td>\n",
       "      <td>0.136985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>0.078851</td>\n",
       "      <td>0.671704</td>\n",
       "      <td>0.234834</td>\n",
       "      <td>0.255941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>0.116590</td>\n",
       "      <td>0.659031</td>\n",
       "      <td>0.209264</td>\n",
       "      <td>0.134794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       neg       neu       pos  compound\n",
       "0    2022-12-02  0.061464  0.772297  0.166158  0.212533\n",
       "1    2022-12-03  0.061216  0.777708  0.161076  0.202205\n",
       "2    2022-12-04  0.043140  0.842057  0.114802  0.142914\n",
       "3    2022-12-05       NaN       NaN       NaN       NaN\n",
       "4    2022-12-06       NaN       NaN       NaN       NaN\n",
       "..          ...       ...       ...       ...       ...\n",
       "115  2023-03-27  0.106032  0.692537  0.190728  0.154342\n",
       "116  2023-03-28  0.096618  0.717403  0.168647  0.149509\n",
       "117  2023-03-29  0.128494  0.649595  0.212027  0.136985\n",
       "118  2023-03-30  0.078851  0.671704  0.234834  0.255941\n",
       "119  2023-03-31  0.116590  0.659031  0.209264  0.134794\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_copy[\"Date\"] = df_daily_copy[\"Date\"].astype(str)\n",
    "df_daily_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_copy.to_json('daily_score_copy.json', orient='records', indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading boto3-1.26.104-py3-none-any.whl (135 kB)\n",
      "     ---------------------------------------- 0.0/135.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 135.6/135.6 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "     ---------------------------------------- 0.0/79.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 79.6/79.6 kB ? eta 0:00:00\n",
      "Collecting botocore<1.30.0,>=1.29.104\n",
      "  Downloading botocore-1.29.104-py3-none-any.whl (10.6 MB)\n",
      "     ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.3/10.6 MB 26.6 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 2.7/10.6 MB 24.7 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 5.0/10.6 MB 28.8 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 7.1/10.6 MB 30.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 8.9/10.6 MB 31.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.6/10.6 MB 31.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.6/10.6 MB 27.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\github\\school\\bigdatabuddies\\venv\\lib\\site-packages (from botocore<1.30.0,>=1.29.104->boto3) (2.8.2)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "     ---------------------------------------- 0.0/140.9 kB ? eta -:--:--\n",
      "     -------------------------------------- 140.9/140.9 kB 8.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\github\\school\\bigdatabuddies\\venv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.104->boto3) (1.16.0)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.26.104 botocore-1.29.104 jmespath-1.0.1 s3transfer-0.6.0 urllib3-1.26.15\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID='AKIARJIOGROB7MVFOYGX'\n",
    "AWS_SECRET_ACCESS_KEY='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'\n",
    "BUCKET_NAME = 'project-analytics-output'\n",
    "\n",
    "def upload_to_s3(file_name):\n",
    "    s3 = boto3.resource('s3',\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        region_name='us-east-1')\n",
    "    bucket = s3.Bucket(BUCKET_NAME)\n",
    "    with open('new_sentiment_topics.json', 'rb') as file:\n",
    "        s3_path = '{}/{}'.format(\"topic\", file_name)\n",
    "        bucket.put_object(Key=s3_path, Body=file)\n",
    "        print(f'{file_name} has been uploaded to S3 as {s3_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_score_copy.json uploaded to S3 as sentiment/daily_score_copy.json\n"
     ]
    }
   ],
   "source": [
    "folder='sentiment'\n",
    "file_name='daily_score_copy.json'\n",
    "\n",
    "with open('daily_score_copy.json', 'rb') as file:\n",
    "    s3_path = '{}/{}'.format(folder, file_name)\n",
    "    bucket.put_object(Key=s3_path, Body=file)\n",
    "    print(f'{file_name} uploaded to S3 as {s3_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
