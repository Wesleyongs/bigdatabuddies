{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Preprocessing\n",
    "import re    # RegEx for removing non-letter characters\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import boto3\n",
    "import collections\n",
    "import json\n",
    "import gensim\n",
    "import time\n",
    "import nltk\n",
    "import html\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from io import StringIO\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.parse.malt import MaltParser\n",
    "from nltk.corpus import words\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursively copy from S3 to Data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2817381454.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    aws s3 cp --recursive s3://bigdatabuddies-glue-output ../Data\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# !aws s3 cp --recursive s3://bigdatabuddies-glue-output ../Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-1680588414414-part-r-00000.csv\n",
      "run-1680588414414-part-r-00001.csv\n",
      "run-1680588414414-part-r-00002.csv\n",
      "run-1680588414414-part-r-00003.csv\n",
      "run-1680588414414-part-r-00004.csv\n",
      "run-1680588414414-part-r-00005.csv\n",
      "run-1680588414414-part-r-00006.csv\n",
      "run-1680588414414-part-r-00007.csv\n",
      "run-1680588414414-part-r-00008.csv\n",
      "run-1680588414414-part-r-00009.csv\n",
      "run-1680588414414-part-r-00010.csv\n",
      "run-1680588414414-part-r-00011.csv\n",
      "run-1680588414414-part-r-00012.csv\n",
      "run-1680588414414-part-r-00013.csv\n",
      "run-1680588414414-part-r-00014.csv\n",
      "run-1680588414414-part-r-00015.csv\n",
      "run-1680588414414-part-r-00016.csv\n",
      "run-1680588414414-part-r-00017.csv\n",
      "run-1680588414414-part-r-00018.csv\n",
      "run-1680588414414-part-r-00019.csv\n",
      "run-1680588414414-part-r-00020.csv\n",
      "run-1680588414414-part-r-00021.csv\n",
      "run-1680588414414-part-r-00022.csv\n",
      "run-1680588414414-part-r-00023.csv\n",
      "run-1680588414414-part-r-00024.csv\n",
      "run-1680588414414-part-r-00025.csv\n",
      "run-1680588414414-part-r-00026.csv\n",
      "run-1680588414414-part-r-00027.csv\n",
      "run-1680588414414-part-r-00028.csv\n",
      "run-1680588414414-part-r-00029.csv\n",
      "run-1680588414414-part-r-00030.csv\n",
      "run-1680588414414-part-r-00031.csv\n",
      "run-1680588414414-part-r-00032.csv\n",
      "run-1680588414414-part-r-00033.csv\n",
      "run-1680588414414-part-r-00034.csv\n",
      "run-1680588414414-part-r-00035.csv\n",
      "run-1680588414414-part-r-00036.csv\n",
      "run-1680588414414-part-r-00037.csv\n",
      "run-1680588414414-part-r-00038.csv\n",
      "run-1680588414414-part-r-00039.csv\n",
      "run-1680588414414-part-r-00040.csv\n",
      "run-1680588414414-part-r-00041.csv\n",
      "run-1680588414414-part-r-00042.csv\n",
      "run-1680588414414-part-r-00043.csv\n",
      "run-1680588414414-part-r-00044.csv\n",
      "run-1680588414414-part-r-00045.csv\n",
      "run-1680588414414-part-r-00046.csv\n",
      "run-1680588414414-part-r-00047.csv\n",
      "run-1680588414414-part-r-00048.csv\n",
      "run-1680588414414-part-r-00049.csv\n",
      "run-1680588414414-part-r-00050.csv\n",
      "run-1680588414414-part-r-00051.csv\n",
      "run-1680588414414-part-r-00052.csv\n",
      "run-1680588414414-part-r-00053.csv\n",
      "run-1680588414414-part-r-00054.csv\n",
      "run-1680588414414-part-r-00055.csv\n",
      "run-1680588414414-part-r-00056.csv\n",
      "run-1680588414414-part-r-00057.csv\n",
      "run-1680588414414-part-r-00058.csv\n",
      "run-1680588414414-part-r-00059.csv\n",
      "run-1680588414414-part-r-00060.csv\n",
      "run-1680588414414-part-r-00061.csv\n",
      "run-1680588414414-part-r-00062.csv\n",
      "run-1680588414414-part-r-00063.csv\n",
      "run-1680588414414-part-r-00064.csv\n",
      "run-1680588414414-part-r-00065.csv\n",
      "run-1680588414414-part-r-00066.csv\n",
      "run-1680588414414-part-r-00067.csv\n",
      "run-1680588414414-part-r-00068.csv\n",
      "run-1680588414414-part-r-00069.csv\n",
      "run-1680588414414-part-r-00070.csv\n",
      "run-1680588414414-part-r-00071.csv\n",
      "run-1680588414414-part-r-00072.csv\n",
      "run-1680588414414-part-r-00073.csv\n",
      "run-1680588414414-part-r-00074.csv\n",
      "run-1680588414414-part-r-00075.csv\n",
      "run-1680588414414-part-r-00076.csv\n",
      "run-1680588414414-part-r-00077.csv\n",
      "run-1680588414414-part-r-00078.csv\n",
      "run-1680588414414-part-r-00079.csv\n",
      "run-1680588414414-part-r-00080.csv\n",
      "run-1680588414414-part-r-00081.csv\n",
      "run-1680588414414-part-r-00082.csv\n",
      "run-1680588414414-part-r-00083.csv\n",
      "run-1680588414414-part-r-00084.csv\n",
      "run-1680588414414-part-r-00085.csv\n",
      "run-1680588451692-part-r-00000.csv\n",
      "run-1680588451692-part-r-00001.csv\n",
      "run-1680588451692-part-r-00002.csv\n",
      "run-1680588451692-part-r-00003.csv\n",
      "run-1680588451692-part-r-00004.csv\n",
      "run-1680588451692-part-r-00005.csv\n",
      "run-1680588451692-part-r-00006.csv\n",
      "run-1680588451692-part-r-00007.csv\n",
      "run-1680588451692-part-r-00008.csv\n",
      "run-1680588451692-part-r-00009.csv\n",
      "run-1680588451692-part-r-00010.csv\n",
      "run-1680588451692-part-r-00011.csv\n",
      "run-1680588451692-part-r-00012.csv\n",
      "run-1680588451692-part-r-00013.csv\n",
      "run-1680588451692-part-r-00014.csv\n",
      "run-1680588451692-part-r-00015.csv\n",
      "run-1680588451692-part-r-00016.csv\n",
      "run-1680588451692-part-r-00017.csv\n",
      "run-1680588451692-part-r-00018.csv\n",
      "run-1680588451692-part-r-00019.csv\n",
      "run-1680588451692-part-r-00020.csv\n",
      "run-1680588451692-part-r-00021.csv\n",
      "run-1680588451692-part-r-00022.csv\n",
      "run-1680588451692-part-r-00023.csv\n",
      "run-1680588451692-part-r-00024.csv\n",
      "run-1680588451692-part-r-00025.csv\n",
      "run-1680588451692-part-r-00026.csv\n",
      "run-1680588451692-part-r-00027.csv\n",
      "run-1680588451692-part-r-00028.csv\n",
      "run-1680588451692-part-r-00029.csv\n",
      "run-1680588451692-part-r-00030.csv\n",
      "run-1680588451692-part-r-00031.csv\n",
      "run-1680588451692-part-r-00032.csv\n",
      "run-1680588451692-part-r-00033.csv\n",
      "run-1680588451692-part-r-00034.csv\n",
      "run-1680588451692-part-r-00035.csv\n",
      "run-1680588451692-part-r-00036.csv\n",
      "run-1680588451692-part-r-00037.csv\n",
      "run-1680588451692-part-r-00038.csv\n",
      "run-1680588451692-part-r-00039.csv\n",
      "run-1680588451692-part-r-00040.csv\n",
      "run-1680588451692-part-r-00041.csv\n",
      "run-1680588451692-part-r-00042.csv\n",
      "run-1680588451692-part-r-00043.csv\n",
      "run-1680588451692-part-r-00044.csv\n",
      "run-1680588451692-part-r-00045.csv\n",
      "run-1680588451692-part-r-00046.csv\n",
      "run-1680588451692-part-r-00047.csv\n",
      "run-1680588451692-part-r-00048.csv\n",
      "run-1680588451692-part-r-00049.csv\n",
      "run-1680588451692-part-r-00050.csv\n",
      "run-1680588451692-part-r-00051.csv\n",
      "run-1680588451692-part-r-00052.csv\n",
      "run-1680588451692-part-r-00053.csv\n",
      "run-1680588451692-part-r-00054.csv\n",
      "run-1680588451692-part-r-00055.csv\n",
      "run-1680588451692-part-r-00056.csv\n",
      "run-1680588451692-part-r-00057.csv\n",
      "run-1680588451692-part-r-00058.csv\n",
      "run-1680588451692-part-r-00059.csv\n",
      "run-1680588451692-part-r-00060.csv\n",
      "run-1680588451692-part-r-00061.csv\n",
      "run-1680588451692-part-r-00062.csv\n",
      "run-1680588451692-part-r-00063.csv\n",
      "run-1680588451692-part-r-00064.csv\n",
      "run-1680588451692-part-r-00065.csv\n",
      "run-1680588451692-part-r-00066.csv\n",
      "run-1680588451692-part-r-00067.csv\n",
      "run-1680588451692-part-r-00068.csv\n",
      "run-1680588451692-part-r-00069.csv\n",
      "run-1680588451692-part-r-00070.csv\n",
      "run-1680588451692-part-r-00071.csv\n",
      "run-1680588451692-part-r-00072.csv\n",
      "run-1680588451692-part-r-00073.csv\n",
      "run-1680588451692-part-r-00074.csv\n",
      "run-1680588451692-part-r-00075.csv\n",
      "run-1680588451692-part-r-00076.csv\n",
      "run-1680588451692-part-r-00077.csv\n",
      "run-1680588451692-part-r-00078.csv\n",
      "run-1680588451692-part-r-00079.csv\n",
      "run-1680588451692-part-r-00080.csv\n",
      "run-1680588451692-part-r-00081.csv\n",
      "run-1680588451692-part-r-00082.csv\n",
      "run-1680588451692-part-r-00083.csv\n",
      "run-1680588451692-part-r-00084.csv\n",
      "run-1680588451692-part-r-00085.csv\n",
      "run-1680588451692-part-r-00086.csv\n",
      "run-1680588451692-part-r-00087.csv\n",
      "run-1680588451692-part-r-00088.csv\n",
      "run-1680588451692-part-r-00089.csv\n",
      "run-1680588451692-part-r-00090.csv\n",
      "run-1680588451692-part-r-00091.csv\n",
      "run-1680588451692-part-r-00092.csv\n",
      "run-1680588451692-part-r-00093.csv\n",
      "run-1680588451692-part-r-00094.csv\n",
      "run-1680588451692-part-r-00095.csv\n",
      "run-1680588451692-part-r-00096.csv\n",
      "run-1680588451692-part-r-00097.csv\n",
      "run-1680588451692-part-r-00098.csv\n",
      "run-1680588451692-part-r-00099.csv\n",
      "run-1680588451692-part-r-00100.csv\n",
      "run-1680588451692-part-r-00101.csv\n",
      "run-1680588451692-part-r-00102.csv\n",
      "run-1680588451692-part-r-00103.csv\n",
      "run-1680588451692-part-r-00104.csv\n",
      "run-1680588451692-part-r-00105.csv\n",
      "run-1680588451692-part-r-00106.csv\n",
      "run-1680588451692-part-r-00107.csv\n",
      "run-1680588451692-part-r-00108.csv\n",
      "run-1680588451692-part-r-00109.csv\n",
      "run-1680588451692-part-r-00110.csv\n",
      "run-1680588451692-part-r-00111.csv\n",
      "run-1680588451692-part-r-00112.csv\n",
      "run-1680588451692-part-r-00113.csv\n",
      "run-1680588451692-part-r-00114.csv\n",
      "run-1680588451692-part-r-00115.csv\n",
      "run-1680588451692-part-r-00116.csv\n",
      "run-1680588451692-part-r-00117.csv\n",
      "run-1680588451692-part-r-00118.csv\n",
      "run-1680588451692-part-r-00119.csv\n",
      "run-1680588451692-part-r-00120.csv\n",
      "run-1680588451692-part-r-00121.csv\n",
      "run-1680588451692-part-r-00122.csv\n",
      "run-1680588451692-part-r-00123.csv\n",
      "run-1680588451692-part-r-00124.csv\n",
      "run-1680588451692-part-r-00125.csv\n",
      "run-1680588451692-part-r-00126.csv\n",
      "run-1680588451692-part-r-00127.csv\n",
      "run-1680588451692-part-r-00128.csv\n",
      "run-1680588451692-part-r-00129.csv\n",
      "run-1680588451692-part-r-00130.csv\n",
      "run-1680588451692-part-r-00131.csv\n",
      "run-1680588451692-part-r-00132.csv\n",
      "run-1680588451692-part-r-00133.csv\n",
      "run-1680588451692-part-r-00134.csv\n",
      "run-1680588451692-part-r-00135.csv\n",
      "run-1680588451692-part-r-00136.csv\n",
      "run-1680588451692-part-r-00137.csv\n",
      "run-1680588451692-part-r-00138.csv\n",
      "run-1680588451692-part-r-00139.csv\n",
      "run-1680588451692-part-r-00140.csv\n",
      "run-1680588451692-part-r-00141.csv\n",
      "run-1680588451692-part-r-00142.csv\n",
      "run-1680588451692-part-r-00143.csv\n",
      "run-1680588451692-part-r-00144.csv\n",
      "run-1680588451692-part-r-00145.csv\n",
      "run-1680588451692-part-r-00146.csv\n",
      "run-1680588451692-part-r-00147.csv\n",
      "run-1680588451692-part-r-00148.csv\n",
      "run-1680588451692-part-r-00149.csv\n",
      "run-1680588451692-part-r-00150.csv\n",
      "run-1680588451692-part-r-00151.csv\n",
      "run-1680588451692-part-r-00152.csv\n",
      "run-1680588451692-part-r-00153.csv\n",
      "run-1680588451692-part-r-00154.csv\n",
      "run-1680588451692-part-r-00155.csv\n",
      "run-1680588451692-part-r-00156.csv\n",
      "run-1680588451692-part-r-00157.csv\n",
      "run-1680588451692-part-r-00158.csv\n",
      "run-1680588451692-part-r-00159.csv\n",
      "run-1680588451692-part-r-00160.csv\n",
      "run-1680588451692-part-r-00161.csv\n",
      "run-1680588451692-part-r-00162.csv\n",
      "run-1680588451692-part-r-00163.csv\n",
      "run-1680588451692-part-r-00164.csv\n",
      "run-1680588451692-part-r-00165.csv\n",
      "run-1680588451692-part-r-00166.csv\n",
      "run-1680588451692-part-r-00167.csv\n",
      "run-1680588451692-part-r-00168.csv\n",
      "run-1680588451692-part-r-00169.csv\n",
      "run-1680588451692-part-r-00170.csv\n",
      "run-1680588451692-part-r-00171.csv\n",
      "run-1680588451692-part-r-00172.csv\n",
      "run-1680588451692-part-r-00173.csv\n",
      "run-1680588451692-part-r-00174.csv\n",
      "run-1680588451692-part-r-00175.csv\n",
      "run-1680588451692-part-r-00176.csv\n",
      "run-1680588451692-part-r-00177.csv\n",
      "run-1680588451692-part-r-00178.csv\n",
      "run-1680588451692-part-r-00179.csv\n",
      "run-1680588451692-part-r-00180.csv\n",
      "run-1680588451692-part-r-00181.csv\n",
      "run-1680588451692-part-r-00182.csv\n",
      "run-1680588451692-part-r-00183.csv\n",
      "run-1680588451692-part-r-00184.csv\n",
      "run-1680588451692-part-r-00185.csv\n",
      "run-1680588451692-part-r-00186.csv\n",
      "run-1680588451692-part-r-00187.csv\n",
      "run-1680588451692-part-r-00188.csv\n",
      "run-1680588451692-part-r-00189.csv\n",
      "run-1680588451692-part-r-00190.csv\n",
      "run-1680588451692-part-r-00191.csv\n",
      "run-1680588451692-part-r-00192.csv\n",
      "run-1680588451692-part-r-00193.csv\n",
      "run-1680588451692-part-r-00194.csv\n",
      "run-1680588451692-part-r-00195.csv\n",
      "run-1680588451692-part-r-00196.csv\n",
      "run-1680588451692-part-r-00197.csv\n",
      "run-1680588451692-part-r-00198.csv\n",
      "run-1680588451692-part-r-00199.csv\n",
      "run-1680588451692-part-r-00200.csv\n",
      "run-1680588451692-part-r-00201.csv\n",
      "run-1680588451692-part-r-00202.csv\n",
      "run-1680588451692-part-r-00203.csv\n",
      "run-1680588451692-part-r-00204.csv\n",
      "run-1680588451692-part-r-00205.csv\n",
      "run-1680588451692-part-r-00206.csv\n",
      "run-1680588451692-part-r-00207.csv\n",
      "run-1680588451692-part-r-00208.csv\n",
      "run-1680588451692-part-r-00209.csv\n",
      "run-1680588451692-part-r-00210.csv\n",
      "run-1680588451692-part-r-00211.csv\n",
      "run-1680588451692-part-r-00212.csv\n",
      "run-1680588451692-part-r-00213.csv\n",
      "run-1680588451692-part-r-00214.csv\n",
      "run-1680588451692-part-r-00215.csv\n",
      "run-1680588451692-part-r-00216.csv\n",
      "run-1680588451692-part-r-00217.csv\n",
      "run-1680588451692-part-r-00218.csv\n",
      "run-1680588451692-part-r-00219.csv\n",
      "run-1680588451692-part-r-00220.csv\n",
      "run-1680588451692-part-r-00221.csv\n",
      "run-1680588451692-part-r-00222.csv\n",
      "run-1680588451692-part-r-00223.csv\n",
      "run-1680588451692-part-r-00224.csv\n",
      "run-1680588451692-part-r-00225.csv\n",
      "run-1680588451692-part-r-00226.csv\n",
      "run-1680588451692-part-r-00227.csv\n",
      "run-1680588451692-part-r-00228.csv\n",
      "run-1680588451692-part-r-00229.csv\n",
      "run-1680588451692-part-r-00230.csv\n",
      "run-1680588451692-part-r-00231.csv\n",
      "run-1680588451692-part-r-00232.csv\n",
      "run-1680588451692-part-r-00233.csv\n",
      "run-1680588451692-part-r-00234.csv\n",
      "run-1680588451692-part-r-00235.csv\n",
      "run-1680588451692-part-r-00236.csv\n",
      "run-1680588451692-part-r-00237.csv\n",
      "run-1680588451692-part-r-00238.csv\n",
      "run-1680588451692-part-r-00239.csv\n",
      "run-1680588451692-part-r-00240.csv\n",
      "run-1680588451692-part-r-00241.csv\n",
      "run-1680588451692-part-r-00242.csv\n",
      "run-1680588451692-part-r-00243.csv\n",
      "run-1680588451692-part-r-00244.csv\n",
      "run-1680588451692-part-r-00245.csv\n",
      "run-1680588451692-part-r-00246.csv\n",
      "run-1680588451692-part-r-00247.csv\n",
      "run-1680588451692-part-r-00248.csv\n",
      "run-1680588451692-part-r-00249.csv\n",
      "run-1680588451692-part-r-00250.csv\n",
      "run-1680588451692-part-r-00251.csv\n",
      "run-1680588451692-part-r-00252.csv\n",
      "run-1680588451692-part-r-00253.csv\n",
      "run-1680588451692-part-r-00254.csv\n",
      "run-1680588451692-part-r-00255.csv\n",
      "run-1680588451692-part-r-00256.csv\n",
      "run-1680588451692-part-r-00257.csv\n",
      "run-1680588451692-part-r-00258.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file in os.listdir('../Data/'):\n",
    "    if file.endswith('.csv'):\n",
    "        print(file)\n",
    "        df = pd.read_csv(os.path.join('../Data/', file))\n",
    "        dfs.append(df)\n",
    "concat_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv(\"../Temp/concat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jewel\\AppData\\Local\\Temp\\ipykernel_24612\\4148428780.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  concat_df = pd.read_csv(\"../Temp/{}_{}_concat.csv\".format(today_str, current_month))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 23:59:58+00:00</td>\n",
       "      <td>1598466969141137408</td>\n",
       "      <td>The new  ChatGPT model by  OpenAI is astonishi...</td>\n",
       "      <td>askviable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 23:59:56+00:00</td>\n",
       "      <td>1598466963466252288</td>\n",
       "      <td>bitquark I am looking forward for a ChatGPT A...</td>\n",
       "      <td>mazen160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 23:59:37+00:00</td>\n",
       "      <td>1598466881761218560</td>\n",
       "      <td>i think i broke chatGPT  it s been frozen for ...</td>\n",
       "      <td>ZoumanaCisse6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 23:59:26+00:00</td>\n",
       "      <td>1598466834776600576</td>\n",
       "      <td>YanoTomo    aizu sniper yae AI             Ch...</td>\n",
       "      <td>papakichi111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 23:59:20+00:00</td>\n",
       "      <td>1598466812198387712</td>\n",
       "      <td>I like ChatGPT as much as the next guy  but th...</td>\n",
       "      <td>DennisLibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663206</th>\n",
       "      <td>2022-11-09 00:00:50+00:00</td>\n",
       "      <td>1590132269255114753</td>\n",
       "      <td>Reduce cost and improve query performance with...</td>\n",
       "      <td>tweepy20220507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663207</th>\n",
       "      <td>2022-11-09 00:00:36+00:00</td>\n",
       "      <td>1590132210715303936</td>\n",
       "      <td>Enable cross account queries on AWS CloudTrail...</td>\n",
       "      <td>tweepy20220507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663208</th>\n",
       "      <td>2022-11-09 00:00:12+00:00</td>\n",
       "      <td>1590132106260353024</td>\n",
       "      <td>If you want to generate more leads  create con...</td>\n",
       "      <td>PirenneSalvor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663209</th>\n",
       "      <td>2022-11-09 00:00:03+00:00</td>\n",
       "      <td>1590132069069619200</td>\n",
       "      <td>AnnaTynan  Yes  bc we share an inbox  I am lu...</td>\n",
       "      <td>ceciliaclyra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663210</th>\n",
       "      <td>2022-11-09 00:00:01+00:00</td>\n",
       "      <td>1590132061792505856</td>\n",
       "      <td>dr veeprakash Upon inquiry about why he wants...</td>\n",
       "      <td>ParthaS01380029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5663211 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datetime                   id  \\\n",
       "0        2022-12-01 23:59:58+00:00  1598466969141137408   \n",
       "1        2022-12-01 23:59:56+00:00  1598466963466252288   \n",
       "2        2022-12-01 23:59:37+00:00  1598466881761218560   \n",
       "3        2022-12-01 23:59:26+00:00  1598466834776600576   \n",
       "4        2022-12-01 23:59:20+00:00  1598466812198387712   \n",
       "...                            ...                  ...   \n",
       "5663206  2022-11-09 00:00:50+00:00  1590132269255114753   \n",
       "5663207  2022-11-09 00:00:36+00:00  1590132210715303936   \n",
       "5663208  2022-11-09 00:00:12+00:00  1590132106260353024   \n",
       "5663209  2022-11-09 00:00:03+00:00  1590132069069619200   \n",
       "5663210  2022-11-09 00:00:01+00:00  1590132061792505856   \n",
       "\n",
       "                                                      text         username  \n",
       "0        The new  ChatGPT model by  OpenAI is astonishi...        askviable  \n",
       "1         bitquark I am looking forward for a ChatGPT A...         mazen160  \n",
       "2        i think i broke chatGPT  it s been frozen for ...    ZoumanaCisse6  \n",
       "3         YanoTomo    aizu sniper yae AI             Ch...     papakichi111  \n",
       "4        I like ChatGPT as much as the next guy  but th...      DennisLibre  \n",
       "...                                                    ...              ...  \n",
       "5663206  Reduce cost and improve query performance with...   tweepy20220507  \n",
       "5663207  Enable cross account queries on AWS CloudTrail...   tweepy20220507  \n",
       "5663208  If you want to generate more leads  create con...    PirenneSalvor  \n",
       "5663209   AnnaTynan  Yes  bc we share an inbox  I am lu...     ceciliaclyra  \n",
       "5663210   dr veeprakash Upon inquiry about why he wants...  ParthaS01380029  \n",
       "\n",
       "[5663211 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df = pd.read_csv(\"../Temp/concat.csv\")\n",
    "concat_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(text):\n",
    "    decoded_text = text.encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # decode HTML entities\n",
    "    decoded_html = html.unescape(decoded_text)\n",
    "    return ''.join([word for word in decoded_html if word.isprintable()])\n",
    "\n",
    "def remove_mentions(text):\n",
    "    return re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "\n",
    "def remove_stopwords(words_list):\n",
    "    stop_list = stopwords.words(\"english\")\n",
    "    stop_list.append(\"filler\")\n",
    "    stop_list.extend([\"html\", \"http\", \"https\", \"www\", \"gt\", \"amp\", \"com\", \"nbsp\", \"em\", \"en\", \"lt\", \"quot\"])\n",
    "    clean_sentence = ''\n",
    "    for word in words_list:\n",
    "        if word not in stop_list:\n",
    "            clean_sentence += word + ' '\n",
    "    return clean_sentence\n",
    "\n",
    "def clean_original_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    decoded_sentence = decode_text(text)\n",
    "    decoded_tokens = decoded_sentence.split()\n",
    "    clean_sentence = remove_stopwords(decoded_tokens)\n",
    "\n",
    "    return clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['clean_text'] = concat_df['text'].apply(clean_original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv(\"../Temp/preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursively copy to Data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2817381454.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    aws s3 cp --recursive s3://bigdatabuddies-glue-output ../Data\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# !aws s3 cp --recursive s3://bigdatabuddies-glue-output ../Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-1680588414414-part-r-00000.csv\n",
      "run-1680588414414-part-r-00001.csv\n",
      "run-1680588414414-part-r-00002.csv\n",
      "run-1680588414414-part-r-00003.csv\n",
      "run-1680588414414-part-r-00004.csv\n",
      "run-1680588414414-part-r-00005.csv\n",
      "run-1680588414414-part-r-00006.csv\n",
      "run-1680588414414-part-r-00007.csv\n",
      "run-1680588414414-part-r-00008.csv\n",
      "run-1680588414414-part-r-00009.csv\n",
      "run-1680588414414-part-r-00010.csv\n",
      "run-1680588414414-part-r-00011.csv\n",
      "run-1680588414414-part-r-00012.csv\n",
      "run-1680588414414-part-r-00013.csv\n",
      "run-1680588414414-part-r-00014.csv\n",
      "run-1680588414414-part-r-00015.csv\n",
      "run-1680588414414-part-r-00016.csv\n",
      "run-1680588414414-part-r-00017.csv\n",
      "run-1680588414414-part-r-00018.csv\n",
      "run-1680588414414-part-r-00019.csv\n",
      "run-1680588414414-part-r-00020.csv\n",
      "run-1680588414414-part-r-00021.csv\n",
      "run-1680588414414-part-r-00022.csv\n",
      "run-1680588414414-part-r-00023.csv\n",
      "run-1680588414414-part-r-00024.csv\n",
      "run-1680588414414-part-r-00025.csv\n",
      "run-1680588414414-part-r-00026.csv\n",
      "run-1680588414414-part-r-00027.csv\n",
      "run-1680588414414-part-r-00028.csv\n",
      "run-1680588414414-part-r-00029.csv\n",
      "run-1680588414414-part-r-00030.csv\n",
      "run-1680588414414-part-r-00031.csv\n",
      "run-1680588414414-part-r-00032.csv\n",
      "run-1680588414414-part-r-00033.csv\n",
      "run-1680588414414-part-r-00034.csv\n",
      "run-1680588414414-part-r-00035.csv\n",
      "run-1680588414414-part-r-00036.csv\n",
      "run-1680588414414-part-r-00037.csv\n",
      "run-1680588414414-part-r-00038.csv\n",
      "run-1680588414414-part-r-00039.csv\n",
      "run-1680588414414-part-r-00040.csv\n",
      "run-1680588414414-part-r-00041.csv\n",
      "run-1680588414414-part-r-00042.csv\n",
      "run-1680588414414-part-r-00043.csv\n",
      "run-1680588414414-part-r-00044.csv\n",
      "run-1680588414414-part-r-00045.csv\n",
      "run-1680588414414-part-r-00046.csv\n",
      "run-1680588414414-part-r-00047.csv\n",
      "run-1680588414414-part-r-00048.csv\n",
      "run-1680588414414-part-r-00049.csv\n",
      "run-1680588414414-part-r-00050.csv\n",
      "run-1680588414414-part-r-00051.csv\n",
      "run-1680588414414-part-r-00052.csv\n",
      "run-1680588414414-part-r-00053.csv\n",
      "run-1680588414414-part-r-00054.csv\n",
      "run-1680588414414-part-r-00055.csv\n",
      "run-1680588414414-part-r-00056.csv\n",
      "run-1680588414414-part-r-00057.csv\n",
      "run-1680588414414-part-r-00058.csv\n",
      "run-1680588414414-part-r-00059.csv\n",
      "run-1680588414414-part-r-00060.csv\n",
      "run-1680588414414-part-r-00061.csv\n",
      "run-1680588414414-part-r-00062.csv\n",
      "run-1680588414414-part-r-00063.csv\n",
      "run-1680588414414-part-r-00064.csv\n",
      "run-1680588414414-part-r-00065.csv\n",
      "run-1680588414414-part-r-00066.csv\n",
      "run-1680588414414-part-r-00067.csv\n",
      "run-1680588414414-part-r-00068.csv\n",
      "run-1680588414414-part-r-00069.csv\n",
      "run-1680588414414-part-r-00070.csv\n",
      "run-1680588414414-part-r-00071.csv\n",
      "run-1680588414414-part-r-00072.csv\n",
      "run-1680588414414-part-r-00073.csv\n",
      "run-1680588414414-part-r-00074.csv\n",
      "run-1680588414414-part-r-00075.csv\n",
      "run-1680588414414-part-r-00076.csv\n",
      "run-1680588414414-part-r-00077.csv\n",
      "run-1680588414414-part-r-00078.csv\n",
      "run-1680588414414-part-r-00079.csv\n",
      "run-1680588414414-part-r-00080.csv\n",
      "run-1680588414414-part-r-00081.csv\n",
      "run-1680588414414-part-r-00082.csv\n",
      "run-1680588414414-part-r-00083.csv\n",
      "run-1680588414414-part-r-00084.csv\n",
      "run-1680588414414-part-r-00085.csv\n",
      "run-1680588451692-part-r-00000.csv\n",
      "run-1680588451692-part-r-00001.csv\n",
      "run-1680588451692-part-r-00002.csv\n",
      "run-1680588451692-part-r-00003.csv\n",
      "run-1680588451692-part-r-00004.csv\n",
      "run-1680588451692-part-r-00005.csv\n",
      "run-1680588451692-part-r-00006.csv\n",
      "run-1680588451692-part-r-00007.csv\n",
      "run-1680588451692-part-r-00008.csv\n",
      "run-1680588451692-part-r-00009.csv\n",
      "run-1680588451692-part-r-00010.csv\n",
      "run-1680588451692-part-r-00011.csv\n",
      "run-1680588451692-part-r-00012.csv\n",
      "run-1680588451692-part-r-00013.csv\n",
      "run-1680588451692-part-r-00014.csv\n",
      "run-1680588451692-part-r-00015.csv\n",
      "run-1680588451692-part-r-00016.csv\n",
      "run-1680588451692-part-r-00017.csv\n",
      "run-1680588451692-part-r-00018.csv\n",
      "run-1680588451692-part-r-00019.csv\n",
      "run-1680588451692-part-r-00020.csv\n",
      "run-1680588451692-part-r-00021.csv\n",
      "run-1680588451692-part-r-00022.csv\n",
      "run-1680588451692-part-r-00023.csv\n",
      "run-1680588451692-part-r-00024.csv\n",
      "run-1680588451692-part-r-00025.csv\n",
      "run-1680588451692-part-r-00026.csv\n",
      "run-1680588451692-part-r-00027.csv\n",
      "run-1680588451692-part-r-00028.csv\n",
      "run-1680588451692-part-r-00029.csv\n",
      "run-1680588451692-part-r-00030.csv\n",
      "run-1680588451692-part-r-00031.csv\n",
      "run-1680588451692-part-r-00032.csv\n",
      "run-1680588451692-part-r-00033.csv\n",
      "run-1680588451692-part-r-00034.csv\n",
      "run-1680588451692-part-r-00035.csv\n",
      "run-1680588451692-part-r-00036.csv\n",
      "run-1680588451692-part-r-00037.csv\n",
      "run-1680588451692-part-r-00038.csv\n",
      "run-1680588451692-part-r-00039.csv\n",
      "run-1680588451692-part-r-00040.csv\n",
      "run-1680588451692-part-r-00041.csv\n",
      "run-1680588451692-part-r-00042.csv\n",
      "run-1680588451692-part-r-00043.csv\n",
      "run-1680588451692-part-r-00044.csv\n",
      "run-1680588451692-part-r-00045.csv\n",
      "run-1680588451692-part-r-00046.csv\n",
      "run-1680588451692-part-r-00047.csv\n",
      "run-1680588451692-part-r-00048.csv\n",
      "run-1680588451692-part-r-00049.csv\n",
      "run-1680588451692-part-r-00050.csv\n",
      "run-1680588451692-part-r-00051.csv\n",
      "run-1680588451692-part-r-00052.csv\n",
      "run-1680588451692-part-r-00053.csv\n",
      "run-1680588451692-part-r-00054.csv\n",
      "run-1680588451692-part-r-00055.csv\n",
      "run-1680588451692-part-r-00056.csv\n",
      "run-1680588451692-part-r-00057.csv\n",
      "run-1680588451692-part-r-00058.csv\n",
      "run-1680588451692-part-r-00059.csv\n",
      "run-1680588451692-part-r-00060.csv\n",
      "run-1680588451692-part-r-00061.csv\n",
      "run-1680588451692-part-r-00062.csv\n",
      "run-1680588451692-part-r-00063.csv\n",
      "run-1680588451692-part-r-00064.csv\n",
      "run-1680588451692-part-r-00065.csv\n",
      "run-1680588451692-part-r-00066.csv\n",
      "run-1680588451692-part-r-00067.csv\n",
      "run-1680588451692-part-r-00068.csv\n",
      "run-1680588451692-part-r-00069.csv\n",
      "run-1680588451692-part-r-00070.csv\n",
      "run-1680588451692-part-r-00071.csv\n",
      "run-1680588451692-part-r-00072.csv\n",
      "run-1680588451692-part-r-00073.csv\n",
      "run-1680588451692-part-r-00074.csv\n",
      "run-1680588451692-part-r-00075.csv\n",
      "run-1680588451692-part-r-00076.csv\n",
      "run-1680588451692-part-r-00077.csv\n",
      "run-1680588451692-part-r-00078.csv\n",
      "run-1680588451692-part-r-00079.csv\n",
      "run-1680588451692-part-r-00080.csv\n",
      "run-1680588451692-part-r-00081.csv\n",
      "run-1680588451692-part-r-00082.csv\n",
      "run-1680588451692-part-r-00083.csv\n",
      "run-1680588451692-part-r-00084.csv\n",
      "run-1680588451692-part-r-00085.csv\n",
      "run-1680588451692-part-r-00086.csv\n",
      "run-1680588451692-part-r-00087.csv\n",
      "run-1680588451692-part-r-00088.csv\n",
      "run-1680588451692-part-r-00089.csv\n",
      "run-1680588451692-part-r-00090.csv\n",
      "run-1680588451692-part-r-00091.csv\n",
      "run-1680588451692-part-r-00092.csv\n",
      "run-1680588451692-part-r-00093.csv\n",
      "run-1680588451692-part-r-00094.csv\n",
      "run-1680588451692-part-r-00095.csv\n",
      "run-1680588451692-part-r-00096.csv\n",
      "run-1680588451692-part-r-00097.csv\n",
      "run-1680588451692-part-r-00098.csv\n",
      "run-1680588451692-part-r-00099.csv\n",
      "run-1680588451692-part-r-00100.csv\n",
      "run-1680588451692-part-r-00101.csv\n",
      "run-1680588451692-part-r-00102.csv\n",
      "run-1680588451692-part-r-00103.csv\n",
      "run-1680588451692-part-r-00104.csv\n",
      "run-1680588451692-part-r-00105.csv\n",
      "run-1680588451692-part-r-00106.csv\n",
      "run-1680588451692-part-r-00107.csv\n",
      "run-1680588451692-part-r-00108.csv\n",
      "run-1680588451692-part-r-00109.csv\n",
      "run-1680588451692-part-r-00110.csv\n",
      "run-1680588451692-part-r-00111.csv\n",
      "run-1680588451692-part-r-00112.csv\n",
      "run-1680588451692-part-r-00113.csv\n",
      "run-1680588451692-part-r-00114.csv\n",
      "run-1680588451692-part-r-00115.csv\n",
      "run-1680588451692-part-r-00116.csv\n",
      "run-1680588451692-part-r-00117.csv\n",
      "run-1680588451692-part-r-00118.csv\n",
      "run-1680588451692-part-r-00119.csv\n",
      "run-1680588451692-part-r-00120.csv\n",
      "run-1680588451692-part-r-00121.csv\n",
      "run-1680588451692-part-r-00122.csv\n",
      "run-1680588451692-part-r-00123.csv\n",
      "run-1680588451692-part-r-00124.csv\n",
      "run-1680588451692-part-r-00125.csv\n",
      "run-1680588451692-part-r-00126.csv\n",
      "run-1680588451692-part-r-00127.csv\n",
      "run-1680588451692-part-r-00128.csv\n",
      "run-1680588451692-part-r-00129.csv\n",
      "run-1680588451692-part-r-00130.csv\n",
      "run-1680588451692-part-r-00131.csv\n",
      "run-1680588451692-part-r-00132.csv\n",
      "run-1680588451692-part-r-00133.csv\n",
      "run-1680588451692-part-r-00134.csv\n",
      "run-1680588451692-part-r-00135.csv\n",
      "run-1680588451692-part-r-00136.csv\n",
      "run-1680588451692-part-r-00137.csv\n",
      "run-1680588451692-part-r-00138.csv\n",
      "run-1680588451692-part-r-00139.csv\n",
      "run-1680588451692-part-r-00140.csv\n",
      "run-1680588451692-part-r-00141.csv\n",
      "run-1680588451692-part-r-00142.csv\n",
      "run-1680588451692-part-r-00143.csv\n",
      "run-1680588451692-part-r-00144.csv\n",
      "run-1680588451692-part-r-00145.csv\n",
      "run-1680588451692-part-r-00146.csv\n",
      "run-1680588451692-part-r-00147.csv\n",
      "run-1680588451692-part-r-00148.csv\n",
      "run-1680588451692-part-r-00149.csv\n",
      "run-1680588451692-part-r-00150.csv\n",
      "run-1680588451692-part-r-00151.csv\n",
      "run-1680588451692-part-r-00152.csv\n",
      "run-1680588451692-part-r-00153.csv\n",
      "run-1680588451692-part-r-00154.csv\n",
      "run-1680588451692-part-r-00155.csv\n",
      "run-1680588451692-part-r-00156.csv\n",
      "run-1680588451692-part-r-00157.csv\n",
      "run-1680588451692-part-r-00158.csv\n",
      "run-1680588451692-part-r-00159.csv\n",
      "run-1680588451692-part-r-00160.csv\n",
      "run-1680588451692-part-r-00161.csv\n",
      "run-1680588451692-part-r-00162.csv\n",
      "run-1680588451692-part-r-00163.csv\n",
      "run-1680588451692-part-r-00164.csv\n",
      "run-1680588451692-part-r-00165.csv\n",
      "run-1680588451692-part-r-00166.csv\n",
      "run-1680588451692-part-r-00167.csv\n",
      "run-1680588451692-part-r-00168.csv\n",
      "run-1680588451692-part-r-00169.csv\n",
      "run-1680588451692-part-r-00170.csv\n",
      "run-1680588451692-part-r-00171.csv\n",
      "run-1680588451692-part-r-00172.csv\n",
      "run-1680588451692-part-r-00173.csv\n",
      "run-1680588451692-part-r-00174.csv\n",
      "run-1680588451692-part-r-00175.csv\n",
      "run-1680588451692-part-r-00176.csv\n",
      "run-1680588451692-part-r-00177.csv\n",
      "run-1680588451692-part-r-00178.csv\n",
      "run-1680588451692-part-r-00179.csv\n",
      "run-1680588451692-part-r-00180.csv\n",
      "run-1680588451692-part-r-00181.csv\n",
      "run-1680588451692-part-r-00182.csv\n",
      "run-1680588451692-part-r-00183.csv\n",
      "run-1680588451692-part-r-00184.csv\n",
      "run-1680588451692-part-r-00185.csv\n",
      "run-1680588451692-part-r-00186.csv\n",
      "run-1680588451692-part-r-00187.csv\n",
      "run-1680588451692-part-r-00188.csv\n",
      "run-1680588451692-part-r-00189.csv\n",
      "run-1680588451692-part-r-00190.csv\n",
      "run-1680588451692-part-r-00191.csv\n",
      "run-1680588451692-part-r-00192.csv\n",
      "run-1680588451692-part-r-00193.csv\n",
      "run-1680588451692-part-r-00194.csv\n",
      "run-1680588451692-part-r-00195.csv\n",
      "run-1680588451692-part-r-00196.csv\n",
      "run-1680588451692-part-r-00197.csv\n",
      "run-1680588451692-part-r-00198.csv\n",
      "run-1680588451692-part-r-00199.csv\n",
      "run-1680588451692-part-r-00200.csv\n",
      "run-1680588451692-part-r-00201.csv\n",
      "run-1680588451692-part-r-00202.csv\n",
      "run-1680588451692-part-r-00203.csv\n",
      "run-1680588451692-part-r-00204.csv\n",
      "run-1680588451692-part-r-00205.csv\n",
      "run-1680588451692-part-r-00206.csv\n",
      "run-1680588451692-part-r-00207.csv\n",
      "run-1680588451692-part-r-00208.csv\n",
      "run-1680588451692-part-r-00209.csv\n",
      "run-1680588451692-part-r-00210.csv\n",
      "run-1680588451692-part-r-00211.csv\n",
      "run-1680588451692-part-r-00212.csv\n",
      "run-1680588451692-part-r-00213.csv\n",
      "run-1680588451692-part-r-00214.csv\n",
      "run-1680588451692-part-r-00215.csv\n",
      "run-1680588451692-part-r-00216.csv\n",
      "run-1680588451692-part-r-00217.csv\n",
      "run-1680588451692-part-r-00218.csv\n",
      "run-1680588451692-part-r-00219.csv\n",
      "run-1680588451692-part-r-00220.csv\n",
      "run-1680588451692-part-r-00221.csv\n",
      "run-1680588451692-part-r-00222.csv\n",
      "run-1680588451692-part-r-00223.csv\n",
      "run-1680588451692-part-r-00224.csv\n",
      "run-1680588451692-part-r-00225.csv\n",
      "run-1680588451692-part-r-00226.csv\n",
      "run-1680588451692-part-r-00227.csv\n",
      "run-1680588451692-part-r-00228.csv\n",
      "run-1680588451692-part-r-00229.csv\n",
      "run-1680588451692-part-r-00230.csv\n",
      "run-1680588451692-part-r-00231.csv\n",
      "run-1680588451692-part-r-00232.csv\n",
      "run-1680588451692-part-r-00233.csv\n",
      "run-1680588451692-part-r-00234.csv\n",
      "run-1680588451692-part-r-00235.csv\n",
      "run-1680588451692-part-r-00236.csv\n",
      "run-1680588451692-part-r-00237.csv\n",
      "run-1680588451692-part-r-00238.csv\n",
      "run-1680588451692-part-r-00239.csv\n",
      "run-1680588451692-part-r-00240.csv\n",
      "run-1680588451692-part-r-00241.csv\n",
      "run-1680588451692-part-r-00242.csv\n",
      "run-1680588451692-part-r-00243.csv\n",
      "run-1680588451692-part-r-00244.csv\n",
      "run-1680588451692-part-r-00245.csv\n",
      "run-1680588451692-part-r-00246.csv\n",
      "run-1680588451692-part-r-00247.csv\n",
      "run-1680588451692-part-r-00248.csv\n",
      "run-1680588451692-part-r-00249.csv\n",
      "run-1680588451692-part-r-00250.csv\n",
      "run-1680588451692-part-r-00251.csv\n",
      "run-1680588451692-part-r-00252.csv\n",
      "run-1680588451692-part-r-00253.csv\n",
      "run-1680588451692-part-r-00254.csv\n",
      "run-1680588451692-part-r-00255.csv\n",
      "run-1680588451692-part-r-00256.csv\n",
      "run-1680588451692-part-r-00257.csv\n",
      "run-1680588451692-part-r-00258.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file in os.listdir('../Data/'):\n",
    "    if file.endswith('.csv'):\n",
    "        print(file)\n",
    "        df = pd.read_csv(os.path.join('../Data/', file))\n",
    "        dfs.append(df)\n",
    "concat_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv(\"../Temp/concat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jewel\\AppData\\Local\\Temp\\ipykernel_24612\\4148428780.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  concat_df = pd.read_csv(\"../Temp/{}_{}_concat.csv\".format(today_str, current_month))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 23:59:58+00:00</td>\n",
       "      <td>1598466969141137408</td>\n",
       "      <td>The new  ChatGPT model by  OpenAI is astonishi...</td>\n",
       "      <td>askviable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 23:59:56+00:00</td>\n",
       "      <td>1598466963466252288</td>\n",
       "      <td>bitquark I am looking forward for a ChatGPT A...</td>\n",
       "      <td>mazen160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 23:59:37+00:00</td>\n",
       "      <td>1598466881761218560</td>\n",
       "      <td>i think i broke chatGPT  it s been frozen for ...</td>\n",
       "      <td>ZoumanaCisse6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 23:59:26+00:00</td>\n",
       "      <td>1598466834776600576</td>\n",
       "      <td>YanoTomo    aizu sniper yae AI             Ch...</td>\n",
       "      <td>papakichi111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 23:59:20+00:00</td>\n",
       "      <td>1598466812198387712</td>\n",
       "      <td>I like ChatGPT as much as the next guy  but th...</td>\n",
       "      <td>DennisLibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663206</th>\n",
       "      <td>2022-11-09 00:00:50+00:00</td>\n",
       "      <td>1590132269255114753</td>\n",
       "      <td>Reduce cost and improve query performance with...</td>\n",
       "      <td>tweepy20220507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663207</th>\n",
       "      <td>2022-11-09 00:00:36+00:00</td>\n",
       "      <td>1590132210715303936</td>\n",
       "      <td>Enable cross account queries on AWS CloudTrail...</td>\n",
       "      <td>tweepy20220507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663208</th>\n",
       "      <td>2022-11-09 00:00:12+00:00</td>\n",
       "      <td>1590132106260353024</td>\n",
       "      <td>If you want to generate more leads  create con...</td>\n",
       "      <td>PirenneSalvor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663209</th>\n",
       "      <td>2022-11-09 00:00:03+00:00</td>\n",
       "      <td>1590132069069619200</td>\n",
       "      <td>AnnaTynan  Yes  bc we share an inbox  I am lu...</td>\n",
       "      <td>ceciliaclyra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663210</th>\n",
       "      <td>2022-11-09 00:00:01+00:00</td>\n",
       "      <td>1590132061792505856</td>\n",
       "      <td>dr veeprakash Upon inquiry about why he wants...</td>\n",
       "      <td>ParthaS01380029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5663211 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datetime                   id  \\\n",
       "0        2022-12-01 23:59:58+00:00  1598466969141137408   \n",
       "1        2022-12-01 23:59:56+00:00  1598466963466252288   \n",
       "2        2022-12-01 23:59:37+00:00  1598466881761218560   \n",
       "3        2022-12-01 23:59:26+00:00  1598466834776600576   \n",
       "4        2022-12-01 23:59:20+00:00  1598466812198387712   \n",
       "...                            ...                  ...   \n",
       "5663206  2022-11-09 00:00:50+00:00  1590132269255114753   \n",
       "5663207  2022-11-09 00:00:36+00:00  1590132210715303936   \n",
       "5663208  2022-11-09 00:00:12+00:00  1590132106260353024   \n",
       "5663209  2022-11-09 00:00:03+00:00  1590132069069619200   \n",
       "5663210  2022-11-09 00:00:01+00:00  1590132061792505856   \n",
       "\n",
       "                                                      text         username  \n",
       "0        The new  ChatGPT model by  OpenAI is astonishi...        askviable  \n",
       "1         bitquark I am looking forward for a ChatGPT A...         mazen160  \n",
       "2        i think i broke chatGPT  it s been frozen for ...    ZoumanaCisse6  \n",
       "3         YanoTomo    aizu sniper yae AI             Ch...     papakichi111  \n",
       "4        I like ChatGPT as much as the next guy  but th...      DennisLibre  \n",
       "...                                                    ...              ...  \n",
       "5663206  Reduce cost and improve query performance with...   tweepy20220507  \n",
       "5663207  Enable cross account queries on AWS CloudTrail...   tweepy20220507  \n",
       "5663208  If you want to generate more leads  create con...    PirenneSalvor  \n",
       "5663209   AnnaTynan  Yes  bc we share an inbox  I am lu...     ceciliaclyra  \n",
       "5663210   dr veeprakash Upon inquiry about why he wants...  ParthaS01380029  \n",
       "\n",
       "[5663211 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df = pd.read_csv(\"../Temp/concat.csv\")\n",
    "concat_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(text):\n",
    "    decoded_text = text.encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # decode HTML entities\n",
    "    decoded_html = html.unescape(decoded_text)\n",
    "    return ''.join([word for word in decoded_html if word.isprintable()])\n",
    "\n",
    "def remove_mentions(text):\n",
    "    return re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "\n",
    "def remove_stopwords(words_list):\n",
    "    stop_list = stopwords.words(\"english\")\n",
    "    stop_list.append(\"filler\")\n",
    "    stop_list.extend([\"html\", \"http\", \"https\", \"www\", \"gt\", \"amp\", \"com\", \"nbsp\", \"em\", \"en\", \"lt\", \"quot\"])\n",
    "    clean_sentence = ''\n",
    "    for word in words_list:\n",
    "        if word not in stop_list:\n",
    "            clean_sentence += word + ' '\n",
    "    return clean_sentence\n",
    "\n",
    "def clean_original_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    decoded_sentence = decode_text(text)\n",
    "    decoded_tokens = decoded_sentence.split()\n",
    "    clean_sentence = remove_stopwords(decoded_tokens)\n",
    "\n",
    "    return clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['clean_text'] = concat_df['text'].apply(clean_original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv(\"../Temp/preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df = pd.read_csv(\"../Temp/preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime          0\n",
       "id                0\n",
       "text             51\n",
       "username          0\n",
       "clean_text    39481\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 23:59:58+00:00</td>\n",
       "      <td>1598466969141137408</td>\n",
       "      <td>The new  ChatGPT model by  OpenAI is astonishi...</td>\n",
       "      <td>askviable</td>\n",
       "      <td>new chatgpt model openai astonishing humanizes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 23:59:56+00:00</td>\n",
       "      <td>1598466963466252288</td>\n",
       "      <td>bitquark I am looking forward for a ChatGPT A...</td>\n",
       "      <td>mazen160</td>\n",
       "      <td>bitquark looking forward chatgpt api see lot t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 23:59:37+00:00</td>\n",
       "      <td>1598466881761218560</td>\n",
       "      <td>i think i broke chatGPT  it s been frozen for ...</td>\n",
       "      <td>ZoumanaCisse6</td>\n",
       "      <td>think broke chatgpt frozen couple minutes co h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 23:59:26+00:00</td>\n",
       "      <td>1598466834776600576</td>\n",
       "      <td>YanoTomo    aizu sniper yae AI             Ch...</td>\n",
       "      <td>papakichi111</td>\n",
       "      <td>yanotomo aizu sniper yae ai chatgpt worldcup c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 23:59:20+00:00</td>\n",
       "      <td>1598466812198387712</td>\n",
       "      <td>I like ChatGPT as much as the next guy  but th...</td>\n",
       "      <td>DennisLibre</td>\n",
       "      <td>like chatgpt much next guy nothing else twitte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime                   id  \\\n",
       "0  2022-12-01 23:59:58+00:00  1598466969141137408   \n",
       "1  2022-12-01 23:59:56+00:00  1598466963466252288   \n",
       "2  2022-12-01 23:59:37+00:00  1598466881761218560   \n",
       "3  2022-12-01 23:59:26+00:00  1598466834776600576   \n",
       "4  2022-12-01 23:59:20+00:00  1598466812198387712   \n",
       "\n",
       "                                                text       username  \\\n",
       "0  The new  ChatGPT model by  OpenAI is astonishi...      askviable   \n",
       "1   bitquark I am looking forward for a ChatGPT A...       mazen160   \n",
       "2  i think i broke chatGPT  it s been frozen for ...  ZoumanaCisse6   \n",
       "3   YanoTomo    aizu sniper yae AI             Ch...   papakichi111   \n",
       "4  I like ChatGPT as much as the next guy  but th...    DennisLibre   \n",
       "\n",
       "                                          clean_text  \n",
       "0  new chatgpt model openai astonishing humanizes...  \n",
       "1  bitquark looking forward chatgpt api see lot t...  \n",
       "2  think broke chatgpt frozen couple minutes co h...  \n",
       "3  yanotomo aizu sniper yae ai chatgpt worldcup c...  \n",
       "4  like chatgpt much next guy nothing else twitte...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = {\n",
    "        'easy-to-use': 10,\n",
    "        'productive': 5,\n",
    "        'slow': -5,\n",
    "        'frustrating': -10,\n",
    "        'glitchy': -100,\n",
    "}\n",
    "\n",
    "# Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "# Update the lexicon\n",
    "vader.lexicon.update(new_words)\n",
    "# Iterate through the headlines and get the polarity scores\n",
    "scores = preprocessed_df['clean_text'].apply(vader.polarity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame.from_records(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets = preprocessed_df.join(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets['datetime'] = pd.to_datetime(scored_tweets['datetime'], utc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 23:59:58+00:00</td>\n",
       "      <td>1598466969141137408</td>\n",
       "      <td>The new  ChatGPT model by  OpenAI is astonishi...</td>\n",
       "      <td>askviable</td>\n",
       "      <td>new chatgpt model openai astonishing humanizes...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 23:59:56+00:00</td>\n",
       "      <td>1598466963466252288</td>\n",
       "      <td>bitquark I am looking forward for a ChatGPT A...</td>\n",
       "      <td>mazen160</td>\n",
       "      <td>bitquark looking forward chatgpt api see lot t...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 23:59:37+00:00</td>\n",
       "      <td>1598466881761218560</td>\n",
       "      <td>i think i broke chatGPT  it s been frozen for ...</td>\n",
       "      <td>ZoumanaCisse6</td>\n",
       "      <td>think broke chatgpt frozen couple minutes co h...</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 23:59:26+00:00</td>\n",
       "      <td>1598466834776600576</td>\n",
       "      <td>YanoTomo    aizu sniper yae AI             Ch...</td>\n",
       "      <td>papakichi111</td>\n",
       "      <td>yanotomo aizu sniper yae ai chatgpt worldcup c...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 23:59:20+00:00</td>\n",
       "      <td>1598466812198387712</td>\n",
       "      <td>I like ChatGPT as much as the next guy  but th...</td>\n",
       "      <td>DennisLibre</td>\n",
       "      <td>like chatgpt much next guy nothing else twitte...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663206</th>\n",
       "      <td>2022-11-09 00:00:50+00:00</td>\n",
       "      <td>1590132269255114753</td>\n",
       "      <td>Reduce cost and improve query performance with...</td>\n",
       "      <td>tweepy20220507</td>\n",
       "      <td>reduce cost improve query performance amazon a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663207</th>\n",
       "      <td>2022-11-09 00:00:36+00:00</td>\n",
       "      <td>1590132210715303936</td>\n",
       "      <td>Enable cross account queries on AWS CloudTrail...</td>\n",
       "      <td>tweepy20220507</td>\n",
       "      <td>enable cross account queries aws cloudtrail la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663208</th>\n",
       "      <td>2022-11-09 00:00:12+00:00</td>\n",
       "      <td>1590132106260353024</td>\n",
       "      <td>If you want to generate more leads  create con...</td>\n",
       "      <td>PirenneSalvor</td>\n",
       "      <td>want generate leads create content answers cus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663209</th>\n",
       "      <td>2022-11-09 00:00:03+00:00</td>\n",
       "      <td>1590132069069619200</td>\n",
       "      <td>AnnaTynan  Yes  bc we share an inbox  I am lu...</td>\n",
       "      <td>ceciliaclyra</td>\n",
       "      <td>annatynan yes bc share inbox lucky get see que...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663210</th>\n",
       "      <td>2022-11-09 00:00:01+00:00</td>\n",
       "      <td>1590132061792505856</td>\n",
       "      <td>dr veeprakash Upon inquiry about why he wants...</td>\n",
       "      <td>ParthaS01380029</td>\n",
       "      <td>dr veeprakash upon inquiry wants us repeat tes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5623679 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         datetime                   id  \\\n",
       "0       2022-12-01 23:59:58+00:00  1598466969141137408   \n",
       "1       2022-12-01 23:59:56+00:00  1598466963466252288   \n",
       "2       2022-12-01 23:59:37+00:00  1598466881761218560   \n",
       "3       2022-12-01 23:59:26+00:00  1598466834776600576   \n",
       "4       2022-12-01 23:59:20+00:00  1598466812198387712   \n",
       "...                           ...                  ...   \n",
       "5663206 2022-11-09 00:00:50+00:00  1590132269255114753   \n",
       "5663207 2022-11-09 00:00:36+00:00  1590132210715303936   \n",
       "5663208 2022-11-09 00:00:12+00:00  1590132106260353024   \n",
       "5663209 2022-11-09 00:00:03+00:00  1590132069069619200   \n",
       "5663210 2022-11-09 00:00:01+00:00  1590132061792505856   \n",
       "\n",
       "                                                      text         username  \\\n",
       "0        The new  ChatGPT model by  OpenAI is astonishi...        askviable   \n",
       "1         bitquark I am looking forward for a ChatGPT A...         mazen160   \n",
       "2        i think i broke chatGPT  it s been frozen for ...    ZoumanaCisse6   \n",
       "3         YanoTomo    aizu sniper yae AI             Ch...     papakichi111   \n",
       "4        I like ChatGPT as much as the next guy  but th...      DennisLibre   \n",
       "...                                                    ...              ...   \n",
       "5663206  Reduce cost and improve query performance with...   tweepy20220507   \n",
       "5663207  Enable cross account queries on AWS CloudTrail...   tweepy20220507   \n",
       "5663208  If you want to generate more leads  create con...    PirenneSalvor   \n",
       "5663209   AnnaTynan  Yes  bc we share an inbox  I am lu...     ceciliaclyra   \n",
       "5663210   dr veeprakash Upon inquiry about why he wants...  ParthaS01380029   \n",
       "\n",
       "                                                clean_text    neg    neu  \\\n",
       "0        new chatgpt model openai astonishing humanizes...  0.000  1.000   \n",
       "1        bitquark looking forward chatgpt api see lot t...  0.000  1.000   \n",
       "2        think broke chatgpt frozen couple minutes co h...  0.237  0.763   \n",
       "3        yanotomo aizu sniper yae ai chatgpt worldcup c...  0.000  1.000   \n",
       "4        like chatgpt much next guy nothing else twitte...  0.000  0.878   \n",
       "...                                                    ...    ...    ...   \n",
       "5663206  reduce cost improve query performance amazon a...    NaN    NaN   \n",
       "5663207  enable cross account queries aws cloudtrail la...    NaN    NaN   \n",
       "5663208  want generate leads create content answers cus...    NaN    NaN   \n",
       "5663209  annatynan yes bc share inbox lucky get see que...    NaN    NaN   \n",
       "5663210  dr veeprakash upon inquiry wants us repeat tes...    NaN    NaN   \n",
       "\n",
       "           pos  compound sentiment  \n",
       "0        0.000    0.0000   neutral  \n",
       "1        0.000    0.0000   neutral  \n",
       "2        0.000   -0.4215  negative  \n",
       "3        0.000    0.0000   neutral  \n",
       "4        0.122    0.3612  positive  \n",
       "...        ...       ...       ...  \n",
       "5663206    NaN       NaN  positive  \n",
       "5663207    NaN       NaN  positive  \n",
       "5663208    NaN       NaN  positive  \n",
       "5663209    NaN       NaN  positive  \n",
       "5663210    NaN       NaN  positive  \n",
       "\n",
       "[5623679 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(score):\n",
    "    if score < 0:\n",
    "        return \"negative\"\n",
    "    elif score == 0:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets['sentiment'] = scored_tweets['compound'].apply(lambda score: label_sentiment(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets_copy = scored_tweets.copy()\n",
    "scored_tweets_copy.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets_copy.to_csv(\"../Temp/sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets_copy.set_index('datetime', inplace=True)\n",
    "\n",
    "# Convert index to timezone-naive\n",
    "scored_tweets_copy.index = scored_tweets_copy.index.tz_localize(None)\n",
    "\n",
    "# Calculate daily averages and create new dataframe\n",
    "df_daily = scored_tweets_copy.resample('D').mean()\n",
    "\n",
    "# Add 'Date' column to new dataframe\n",
    "df_daily['Date'] = df_daily.index.date\n",
    "\n",
    "# Reset index (index is still timezone-naive)\n",
    "df_daily.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "df_daily = df_daily[['Date', 'neg', 'neu', 'pos', 'compound']]\n",
    "df_daily[\"Date\"] = df_daily[\"Date\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.to_json('../Temp/daily_score.json', orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID=AWS_ACCESS_KEY_ID\n",
    "AWS_SECRET_ACCESS_KEY=AWS_SECRET_ACCESS_KEY\n",
    "BUCKET_NAME = BUCKET_NAME\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name='us-east-1')\n",
    "\n",
    "BUCKET = s3.Bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Temp/daily_score.json', 'rb') as file:\n",
    "    s3_path = '{}/{}'.format('sentiment', 'daily_score.json')\n",
    "    BUCKET.put_object(Key=s3_path, Body=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "senti_df = pd.read_csv(\"../Temp/sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "datetime      0\n",
       "id            0\n",
       "text          0\n",
       "username      0\n",
       "clean_text    0\n",
       "neg           0\n",
       "neu           0\n",
       "pos           0\n",
       "compound      0\n",
       "sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    senti_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "except:\n",
    "    senti_df = senti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = senti_df.groupby(\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_topic_terms(grouped_df):\n",
    "    sentiment_topic_terms = {}\n",
    "\n",
    "    for sentiment, sentiment_df in grouped_df:\n",
    "        print(sentiment)\n",
    "        topic_terms = generate_sentiment_topic_model(sentiment_df)\n",
    "        sentiment_topic_terms[sentiment] = topic_terms \n",
    "        \n",
    "    return sentiment_topic_terms\n",
    "    \n",
    "def generate_sentiment_topic_model(df):\n",
    "    chatgptreddit_vecs, chatgptreddit_dict = create_lda_vecs(df)\n",
    "    topic_terms_dict = get_topic_terms(chatgptreddit_vecs, chatgptreddit_dict)\n",
    "    \n",
    "    return topic_terms_dict\n",
    "\n",
    "\"\"\" Functions for LDA topic modelling \"\"\"\n",
    "def docs2vecs(docs, dictionary):\n",
    "    # docs is a list of documents returned by corpus2docs.\n",
    "    # dictionary is a gensim.corpora.Dictionary object.\n",
    "    vecs = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    return vecs\n",
    "\n",
    "def create_lda_vecs(df):\n",
    "    chatgptreddit_docs = []\n",
    "    for doc in df[\"clean_text\"]:\n",
    "        try:\n",
    "            tokens = doc.split()  # split the sentence into a list of tokens\n",
    "            tokens = [token for token in tokens]\n",
    "            chatgptreddit_docs.append(tokens)\n",
    "        except:\n",
    "            continue\n",
    "    chatgptreddit_dict = gensim.corpora.Dictionary(chatgptreddit_docs)\n",
    "    chatgptreddit_vecs = docs2vecs(chatgptreddit_docs, chatgptreddit_dict)\n",
    "    return chatgptreddit_vecs, chatgptreddit_dict\n",
    "\n",
    "def get_topic_terms(chatgptreddit_vecs, chatgptreddit_dict):\n",
    "    chatgptreddit_lda = gensim.models.ldamodel.LdaModel(corpus=chatgptreddit_vecs, id2word=chatgptreddit_dict, num_topics=2)\n",
    "    topic_terms_dict = defaultdict(list)\n",
    "    for topic_id, terms_list in chatgptreddit_lda.show_topics(num_topics=2, num_words=10, formatted=False):\n",
    "        terms = []\n",
    "        for term in terms_list:\n",
    "            # if no variations of the word are found\n",
    "            if len(term[0]) > 1 and term[0] in nltk_words:\n",
    "                terms.append((term[0].lower(), term[1]))\n",
    "        sorted_terms = sorted(terms, key=lambda x: x[1], reverse=True)\n",
    "        topic_terms_dict[\"Topic \" + str(topic_id)] = sorted_terms\n",
    "    topic_terms_dict = dict(topic_terms_dict)\n",
    "    return topic_terms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "neutral\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "sentiment_topic_terms = get_sentiment_topic_terms(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../Temp/sentiment_topics.json', \"w\") as new_file:\n",
    "    output_dict = {}\n",
    "    for sentiment, topics in sentiment_topic_terms.items():\n",
    "        topic_dict = {}\n",
    "        for topic_id, terms in topics.items():\n",
    "            term_list = []\n",
    "            for term in terms:\n",
    "                print()\n",
    "                term_dict = {\"word\": term[0], \"frequency\": round(float(term[1]), 4) }\n",
    "                term_list.append(term_dict)\n",
    "            topic_dict[topic_id] = term_list\n",
    "        output_dict[sentiment] = topic_dict\n",
    "    json.dump(output_dict, new_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID=AWS_ACCESS_KEY_ID\n",
    "AWS_SECRET_ACCESS_KEY=AWS_SECRET_ACCESS_KEY\n",
    "BUCKET_NAME = BUCKET_NAME\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name='us-east-1')\n",
    "\n",
    "BUCKET = s3.Bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Temp/sentiment_topics.json', 'rb') as file:\n",
    "    s3_path = '{}/{}'.format('topic', 'sentiment_topics.json')\n",
    "    BUCKET.put_object(Key=s3_path, Body=file)\n",
    "print('Completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
